{"pages":[{"title":"All Categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"HTTP 완벽가이드 1장","text":"1장 HTTP개관1.1 HTTP: 인터넷의 멀티미디어 배달부HTTP는 신뢰성 있는 데이터 전송 프로토콜을 사용하기 때문에, 데이터가 지구 반대편에서 오더라도 전송 중 손상되거나 꼬이지 않음을 보장한다. 1.2 웹 클라이언트와 서버웹 서버는 HTTP 프로토콜로 의사소통하기 때문에 HTTP서버라고 불린다. 웹 서버는 인터넷의 데이터를 저장하고, HTTP 클라이언트가 요청한 데이터를 제공한다 . 1.3 리소스웹 서버는 웹 리소스를 관리하고 제공한다. 웹 리소스는 텍스트, 이미지 파일 등과 같은 정적 파일과 리소스는 웹에 콘텐츠를 제공하는 어떤 종류든 해당한다. 1.3.1 미디어 타입HTTP는 웹에서 전송되는 객체 각각에 MIME라는 타입의 라벨을 붙인다. 웹브라우저는 서버로부터 객체를 돌려 받을 때, 다룰 수 있는 객체인지 MIME를 통해서 확인한다. 주 타입/부 타입으로 이루어진 문자열 라벨이다. text/html → HTML로 작성된 텍스트 문서 text/plain → plain ASCII 텍스트 문서 image/jpeg →JPEG 이미지 등 수백 가지가 존재한다. 1.3.2 URI통합 자원 식별자(Uniform Resource Identifier) 웹 서버 리소스는 각자 이름을 갖고 있기 때문에 정보 리소스를 고유하게 식별하고 위치를 지정할 수 있다. URI에는 URL과 URN 두가지가 존재한다. 1.3.3 URL통합 자원 지시자(Uniform Resource Locator)는 리소스 식별자의 가장 흔한 형태로, 특정 서버의 한 리소스에 대해 구체적인 위치를 서술한다. 대부분의 URL은 세부분으로 이루어진 표준 포맷을 따른다. 첫번째 부분은 스킴(scheme)으로 리소스에 접근하기 위한 프로토콜을 서술한다. HTTP 프로토콜(http://)이 이에 해당한다. 두번째 부분은 서버의 인터넷 주소를 제공한다. (www.joes-hardware.com) 세번째 부분은 웹 서버의 리소스를 가리킨다.(/image.gif) 오늘날 대부분의 URI는 URL이다. 1.3.4 URN유니폼 리소스 이름(Uniform Resource Name) 리소스의 위치에 영향을 받지 않으며, 리소스가 그 이름을 변하지 않게 유지하는 한, 여러종류의 네트워크 접속 프로토콜로 접근해도 문제가 되지 않는다. 1.4. 트랜잭션요청명령(클라이언트 → 서버)과 응답결과(서버 → 클라이언트)로 구성되어있다. 1.4.1 메서드HTTP는 여러가지 종류의 요청 명령을 지원한다. HTTP요청 메시지는 한 개의 메서드를 갖으며, 서버에게 어떤 동작을 해야하는지 알려준다. GET : 서버에서 클라이언트로 지정한 리소스로 보내라. PUT : 클라이언트에서 서버로 보낸 데이터를 지정한 이름의 리소스로 저장하라. DELETE : 저장한 리소스를 서버에서 삭제하라. POST : 클라이언트 데이터를 서버 게이트웨이 애플리케이션으로 보내라. HEAD : 지정한 리소스에 대한 응답에서 HTTP헤더 부분만 보내라. 1.4.2 상태코드모든 응답 메시지는 상태 코드와 함께 반환된다. 숫자 코드 + 사유구절(reason phrase)로 함께 보낸다. ex) 200 OK , 404 Request Error…. 1.5 메시지 시작줄(Start Line)메시지의 첫 줄로, 요청이라면 무엇을 해야 하는지 응답이라면 무슨 일이 일어났는지 나타낸다. 헤더(Header)0개 이상의 헤더 필드가 나타난다. [이름] : [값] 형태로 구성된다. 헤더에 필드를 추가하기 위해서는 한 줄만 추가하면 된다. 본문(Body)요청 본문은 웹 서버로 데이터를 포함해서 보내며, 응답 본문은 클라이언트로 데이터를 반환한다. 본문은 이진 데이터를 포함할 수 있다.(이미지, 비디오, 오디오, 등) 1.6 TCP 커넥션메시지가 어떻게 TCP 커넥션을 통하는지 알아본다. 1.6.1 TCP/IPHTTP는 애플리케이션 계층 프로토콜이다. HTTP는 네트워크 통신의 핵심적인 세부사항에 대해서는 신경쓰지 않지만 대중적이고 신뢰적인 인터넷 전송 프로토콜인 TCP/IP에게 맡긴다. TCP특징 오류 없는 데이터 전송 순서에 맞는 전달(데이터는 언제나 보낸 순서대로 도착한다) 조각나지 않는 데이터 스트림(언제든 어떤 크기로든 보낼 수 있다) TCP/IP는 패킷 교환 네트워크 프로토콜의 집합이다. 어떤 종류의 컴퓨터나 네트워크든 서로 신뢰성 있는 의사소통을 하게 해준다. TCP커넥션이 맺어지면, 클라이언트와 서버간에 교환되는 메시지가 없어지거나, 손상되거나, 순서가 뒤바뀌어 수신되는 일은 없다. 1.6.2 접속, IP주소 그리고 포트번호HTTP 클라이언트가 서버에 메시지를 전송하기 전에 인터넷 프로토콜 주소와 포트번호를 사용해 클라이언트와 서버사이에 TCP 커넥션을 맺어야한다. 서버에서 클라이언트에게 HTML리소스를 보여주는 과정은 다음과 같다. 웹브라우저는 서버의 URL에서 호스트 명을 추출한다. 웹브라우저는 서버의 호스트 명을 IP로 변환한다. 웹브라우저는 URL에서 포트번호를 추출한다. 웹브라우저는 웹 서버와 TCP 커넥션을 맺는다. 웹브라우저는 서버에 HTTP 요청을 보낸다. 서버는 웹브라우저에 HTTP 응답을 돌려준다. 커넥션이 닫히면, 웹브라우저는 문서를 보여준다. 1.7 웹의 구성요소1.7.1 프락시(Proxy)웹 보안, 애플리케이션 통합, 성능 최적화를 위한 중요한 구성 요소로서, 프락시는 클라이언트와 서버 사이에 위치하여, 클라이언트의 모든 HTTP요청을 받아 서버에 전달한다. 주로 보안을 위해서 많이 사용된다. 모든 웹 트래픽 흐름 속에서 신뢰할 만한 중개자 역할을 한다. 1.7.2 캐시(Cache)웹 캐시와 캐시 프락시는 자신을 거쳐 가는 문서들 중 자주 찾는 것의 사본을 저장해 둔다. 클라이언트는 멀리 떨어진 웹 서버보다 근처의 캐시에서 문서를 빠르게 다운 받을 수 있다. 1.7.3 게이트웨이(Gateway)다른 서버들의 중개자로 동작하는 특별한 서버로서, HTTP 트래픽을 다른 프로토콜로 변환하기 위해 사용된다. 스스로가 리소스를 갖고 있는 진짜 서버인 것처럼 요청을 다룬다. 클라이언트는 자신이 게이트웨이와 통신하고 있음을 알아채지 못한다. 1.7.4 터널두 커넥션 사이에서 raw데이터를 열어보지 않고 그대로 전달해주는 HTTP 애플리케이션이다. 터널은 주로 비 HTTP 데이터를 하나 이상의 HTTP 연결을 통해 그대로 전송해주기 위해 사용된다. 1.7.5 에이전트사용자를 위해 HTTP 요청을 만들어주는 클라이언트 프로그램이다.","link":"/2019/08/03/http-guide-chap1/"},{"title":"HTTP 완벽가이드 10장","text":"10장 HTTP/2.01. HTTP/2.0의 등장 배경HTTP/1.1의 특징 메시지 포맷 단순성과 접근성에 중심을 두고 최적화 되었다. 커넥션 하나를 통해서 요청&amp;응답을 하므로 회전 지연(latency)을 피할수 없다. 2. 개요 HTTP/2.0은 서버와 클라이언트 사이의 TCP커넥션 위에서 동작한다. 요청과 응답은 스트림을 통해 보내지며, 하나의 커넥션에 여러개의 스트림이 동시에 만들어질 수 있다. 스트림에 대한 흐름 제어와 우선순위 부여 기능을 제공한다. 서버는 클라이언트에게 필요하다고 생각하는 리소스라면 그에 대한 요청을 명시적으로 받지 않더라도 능동적으로 클라이언트게 보내줄 수 있다. 3. HTTP/1.1과의 차이점3.1 프레임 HTTP/2.0에서 모든 메시지는 프레임에 담겨 전송된다. R: 예약된 2비트 필드, 값의 의미가 정의되어 있지 않으며, 반드시 0이어 한다. 길이: 페이로드의 길이를 나타내는 14비트 무부호 정수 종류: 프레임의 종류 플래그: 플래그 값의 의미는 프레임의 종류에 따라 다르다. R: 예약된 1비트 필드, 값의 의미가 정의되어 있지 않으며, 반드시 0이어야 한다. 스트림 식별자: 31비트 스트림 식별자, 커넥션 전체와 연관된 프레임을 의미한다. 3.2 스트림과 멀티플렉싱 HTTP/2.0 커넥션을 통해 클라이언트와 서버 사이에서 교환되는 프레임들의 독립된 양방향 시퀀스 한쌍의 HTTP요청과 응답은 하나의 스트림을 통해 이루어진다. 하나의 커넥션에 여러 개의 스트림이 동시에 열릴 수 있다. 스트림은 우선순위 따라서 요청이 처리 될 수 있다. 3.3 헤더 압축 과거에는 웹페이지 방문시에 요청이 많지 않았기 때문에 헤더의 크기가 큰 문제가 되지 않았으나, 최근에는 웹페이지 하나에 수십, 수백개의 요청이 이루어지므로 헤더의 크기가 회전 지연과 대역폭에 영향을 끼친다. HTTP/2.0에서는 메시지의 헤더를 합축하여 전송한다. 3.4 서버 푸시 HTTP/2.0은 서버가 하나의 요청에 대한 응답으로 여러 개의 리소스를 보낼 수 있도록 해준다. 서버가 클라이언트에게 어떤 리소스를 요구할 것인지 미리 알 수 있는 상황에서 유용하다.","link":"/2019/10/27/http-guide-chap10/"},{"title":"HTTP 완벽가이드 12장","text":"12장 기본인증 목표 : HTTP 인증과 그것의 기본이 되는 기본 인증을 알아본다. 1. 인증1.1 HTTP의 인증요구/응답 프레임워크 1.2 인증 프로토콜과 헤더 HTTP에는 기본 인증과 다이제트스트 인증이 존재한다. 단계 헤더 설명 메서드/상태 요청 첫 번째 요청에는 인증 정보가 없다 GET 인증요구 WWW-Authenticate GET 서버는 사용자에게 사용자 이름과 비밀번호를 제공하라는 의미로 401 상태 정보와 함께 요청을 반려한다. 401 Unauthorized 인증 Authorization 클라이언트는 인증 알고리즘과 사용자 이름,비밀번호를 기술한 Authorization 헤더를 보낸다. GET 성공 Authentication-Info 인증 정보가 정확하면, 서버는 문서와 함께 응답한다. 200 OK 2. 기본 인증 기본 인증은 HTTP/1.0에 기술되어 있었지만, RFC 2617로 옮겨졌다. 2.1 기본 인증의 예 사용자가 리소스를 요청한다. 서버가 WWW-Authenticate 헤더와 함께 리소스를 접근하는데 필요한 비밀번호를 요구하는 401 Authorization Required 응답을 반환한다. 브라우저에서 401 응답을 받고 사용자 이름과 비밀번호를 입력하는 화면을 띄운다. 브라우저는 정보들을 콜론으로 이어 붙이고, base-64방식으로 인코딩하고, Authorization 헤더에 그 값을 담아 서버로 다시 보낸다. 서버는 사용자 이름과 비밀번호를 디코딩하고, 그 값이 정확한지 확인하고, 문제 없으면 HTTP 200 OK 메시지와 함께 요청받았던 문서를 보낸다. 2.2 Base-64 사용자 이름/비밀번호 인코딩 HTTP 기본 인증은 사용자 이름과 비밀번호를 클론으로 이어서 합치고, base-64인 코딩 메서드를 사용해 인코딩 한다. base-64 인코딩은 8비트 바이트로 이루어져 있는 시퀀스를 6비트 덩어리의 시퀀스로 변환한다. base-64 인코딩은 국제 문제나 HTTP 헤더에서 사용할 수 없는 문자를 보내야 할 때 유용하다. 2.3 프락시 인증 중개 프락시 서버를 통해 인증 할 수 있다. 프락시 서버에서 접근 정책을 중앙 관리 할 수 있기 때문에, 회사 리소스 전체에 대해 통합적인 접근 제어를 하기 위해서 프락시 서버를 사용하면 좋다. 3. 기본 인증의 보안 결함 기본 인증은 사용자 이름과 비밀번호를 쉽게 디코딩 할 수 있는 형식이므로 노출되어서는 안된다. 메시지의 인증 헤더를 건드리지 않고, 그 외 다른 부분을 수정해서 트랜잭션의 본래 의도를 바꿔버리는 프락시나 중개자가 중간에 개입하는 경우, 기본 인증은 정상적인 동작을 보장하지 않는다.","link":"/2019/11/24/http-guide-chap12/"},{"title":"HTTP 완벽가이드 14장","text":"14장 보안 HTTP 목표: HTTP 트랜잭션을 안전하게 보호하는 더 복잡한 기술들을 알아본다. 1. HTTP를 안전하게 만들기 사용자들이 온라인 쇼핑이나 인터넷뱅킹을 안심하고 사용하기 위해서는 강력한 보안이 필요하다. HTTP의 보안 버전은 효율적이고, 이식성이 좋으며, 관리가 쉽고, 현실 세계의 변화에 대한 적응력이 좋아야 한다. 1.1 HTTPS 모든 HTTP 요청과 응답 데이터는 네트워크로 보내지기 전에 암호화 된다. HTTP의 하부의 보안 계층에서 안전 소켓 계층(Secure Sockets Lyaer, SSL) 또는 전송 계층 보안(Transport Layer Security, TLS)에서 동작한다. 어려운 인코딩 및 디코딩 작업은 SSL 라이브러리 안에서 동작하므로 클라이언트와 서버가 크게 변경할 필요는 없다. 2. 디지털 암호학2.1 암호학 용어들 암호: 테스트를 아무나 키: 암호의 동작을 변경하는 숫자로 된 매개변수 대칭키 암호 체계: 인코딩과 디코딩에 같은 키를 사용하는 알고리즘 비대칭키 암호 체계: 인코딩과 디코딩에 다른 키를 사용하는 알고리즘 공개키 암호법: 비밀 메시지를 전달하는 수백만 대의 컴퓨터를 쉽게 만들 수 있는 시스템 디지털 서명: 메시지가 위조 혹은 변조되지 않았음을 인증하는 체크섬 디지털 인증서: 신뢰할 만한 조직에 의해 서명되고 검증된 신원 확인 정보 2.2 암호(cipher) 암호란 메시지를 인코딩하는 어떤 특정한 방법과 그 비밀 메시지를 디코딩하는 방법이다. 암호가 적용되어 있는 메시지를 텍스트 혹은 평문이라고 한다. 암호는 상대적으로 간단한 알고리즘으로 시작해 기술의 진보에 따라 복잡한 암호를 빠르고 정확하게 인코딩&amp;디코딩 하는 기계를 만들었다. 2.3 키가 있는 암호 디코딩 과정을 바르게 동작시키려면 올바른 키를 암호 기계에 입력할 필요가 있다. 암호키는 하나의 암호 기계를 여러 가상 암호 기계의 집합처럼 만든다. 서로 다른 키 값을 가지고 있으므로 제각기 다르게 동작한다. 2.4 디지털 암호 속도 및 기능에 대한 기계 장치의 한계에서 벗어나, 복잡한 인코딩과 디코딩 알고리즘이 가능하다. 단일 암호 알고리즘으로 키의 값마다 다른 수조 개의 가상 암호 알고리즘을 만들어낼 수 있다. 3. 대칭키 암호법 디지털 알고리즘은 인코딩 할 때와 디코딩 할 때 똑같은 키를 사용하므로 대칭키 암호라 불린다. 발송자와 수신자 모두 통신을 위해 비밀 키를 똑같이 공유 할 필요가 있다. 발송자는 메시지를 암호화 하고 그 결과인 암호문을 수신자에게 발송하기 위해 비밀키를 사용한다. 수신자는 암호문을 받은 뒤 공유키를 사용하여 원래대로 복원하기 위해 해독 함수를 적용한다. 4. 공개키 암호법 두 개의 비대칭 키로 하나는 인코딩시에 다른 하나는 디코딩시에 사용한다. 호스트만이 개인 디코딩 키를 알고 있다. 4.1 RSA 공개키 가로채서 얻은 암호문의 일부(네트워크 스누핑해서 획득) 메시지와 그것을 암호화한 암호문 → 공개키 비대칭 암호는 위 항목들을 알아도 계산할 수 없다는 것을 확신시켜 줘야한다. 그 중 RSA는 공개키 암호 체계중 유명하며, 가장 상용화된 알고리즘이다. 4.2 혼성 암호 체계와 세션 키 공개키 암호 방식의 알고리즘은 계산이 느린 경향이 있다. 실제로는 대칭과 비대칭 방식을 섞은 것이 쓰인다. 5. 디지털 서명 메시지가 위조되지 않았음을 증명하기 위해 메시지에 서명을 하도록 한다. 보안 인증서에 중요하다. 5.1 서명은 암호 체크섬 서명은 메시지를 작성한 저자가 누군지 알려준다. 서명은 메시지 위조를 방지한다. 디지털 서명은 보통 비대칭 공개키에 의해 생성된다. 저자의 개인키는 지문처럼 사용된다. 6. 디지털 인증서신뢰할 수 있는 기관으로부터 보증 받은 사용자나 회사에 대한 정보를 담는다. 6.1 인증서의 내부 대상의 이름, 유효기간, 인증서 발급자, 디지털 서명과 같이 기본적인 것들을 담고 있다. 누구나 디지털 인증서를 만들 수 있지만, 인증서의 정보를 보증하고 인증서를 개인 키로 서명할 수 있는 널리 인정받는 서명 권한을 얻을 수 있는 것은 아니다.","link":"/2019/12/01/http-guide-chap14/"},{"title":"HTTP 완벽가이드 15장","text":"15장 엔터티와 인코딩 목표: 엔터티 및 그와 연관된 엔터티 헤더들이 콘텐츠를 나르기 위해 하는 일들을 알아본다. 1. 메시지는 컨테이너🗄, 엔터티는 화물📦 HTTP 메시지를 인터넷 운송 시스템의 컨테이너라고 생각한다면, HTTP 엔터티는 메시지의 실질적인 화물이다. 엔터티 헤더는 18자(Content-Length:18)의 플레인 텍스트 문서를 의미한다. **`메시지 엔터티는 엔터티 헤더와 엔터티 본문으로 이루어진다!`**엔터티 본문 가공되지 않은 데이터만을 담고 있다. 헤더 필드의 끝을 의미하는 빈 CRLF 줄 바로 다음부터 시작한다. 2. Content-Length: 엔터티의 길이 메시지의 엔터티 본문의 크기를 바이트 단위로 나타낸다. 엔터티 본문을 포함한 메시지에서는 필수적으로 존재해야 한다. 서버 충돌로 인해 메시지가 잘렸는지 감지하고자 할 때와 지속 커넥션을 공유하는 메시지를 올바르게 분할하고자 할 때 필요하다. 2.1 잘림 검출 Content-Length가 없다면 클라이언트는 커넥션이 정상적으로 닫힌 것인지 메시지 전송 중에 서버에 충돌이 발생한 것인지 구분하지 못한다. 메시지 잘림을 검출하기 위해 Content-Length가 필요하다. 2.2 Content-Length와 지속 커넥션(Persistent Connection) Content-Length는 지속 커넥션을 위해 필수이다. 응답이 지속 커넥션을 통해서 온 것이라면, 또 다른 HTTP 응답이 즉시 그 뒤를 이어서 온다. HTTP 애플리케이션은 Content-Length 헤더 없이는 어디까지가 본문이고 다음 메시지인지 알지 못한다. 2.3 콘텐츠 인코딩 HTTP는 보안을 강화하거나 압축을 통해 공간을 절약하도록, 엔터티 본문을 인코딩할 수 있게 해준다. 본문의 콘텐츠가 인코딩되어 있다면, Content-Length 헤더는 인코딩된 본문의 길이를 바이트 단위로 정의한다. 3. 엔터티 요약 HTTP는 불완전한 트랜스코딩 프락시나 버그 많은 중개자 프락시를 비롯한 여러가지 이유로 메시지의 일부분이 전송 중에 변형되는 이리 나타난다. 엔터티 본문 데이터에 대한 의도하지 않은 변경을 감지하기 위해, 최초 엔터티가 생성될 때 송신자는 데이터에 대한 체크섬을 생서할 수 있고, 수신자는 모든 의도하지 않은 엔터티의 변경을 잡아내기 위해 체크섬으로 기본적인 검사를 할 수 있다. Content-MD5 헤더는 서버가 엔터티 본문에 MD5 알고리즘을 적용한 결과를 보내기 위해 사용된다. 4. 미디어 타입과 차셋(Charset) Content-Type 헤더 필드는 엔터티 본문의 MIME 타입을 기술한다. MIME? 전달되는 테이터 매체의 기저형식의 표준화된 이름이다. ex) HTML파일, 워드 문서, MPEG 비디오 등 주 미디어타입 / 부 타입 으로 구성된다. text/html, text/plain, image/gif, image/jpeg 등 4.1 텍스트 매체를 위한 문자 인코딩 엔터티 비트 집합을 텍스트 파일의 글자들로 변환하기 위한 charset 매개변수가 대표적인 예이다. Content-Type: text/html; charset=iso-8859-4 4.2 멀티파트 폼 제출 HTTP 폼을 채워서 제출하면, 가변 길이 텍스트 필드와 업로드 될 객체는 각각 멀티파트 본문을 구성하는 하나의 파트가 되어 보내진다. Content-Type: multipart/form-data; boundary=[abcdefghijklmnopqrstuvwxyz] 5. 콘텐츠 인코딩 HTTP 애플리케이션은 때때로 콘텐츠를 보내기 전에 인코딩을 한다. 5.1 콘텐츠 인코딩 과정 웹 서버가 원본 Content-Type과 Content-Length 헤더를 수반한 원본 응답 메시지를 생성한다. 콘텐츠 인코딩 서버가 인코딩된 메시지를 생성한다. 콘텐츠 인코딩 서버는 Content-Encoding헤더를 인코딩된 메시지에 추가하여, 수신 측 애플리케이션이 그것을 디코딩할 수 있도록 한다. 수신 측 애플리케이션은 인코딩된 메시지를 받아서 디코딩하고 원본을 얻는다. 5.2 콘텐츠 인코딩 유형 인코딩은 각 콘텐츠 인코딩 알고리즘에 고유한 토큰을 할당하는 IANA를 통해 표준화된다. gzip → 가장 효율적이고 널리 쓰이는 압축 알고리즘 compress deflate identity 5.3 Accept-Encoding 헤더 클라이언트는 자신이 지원하는 인코딩의 목록을 Accept-Encoding 요청 헤더를 통해 전달한다. 예).. Accept-Encoding: compress, gzip Accept-Encoding: Accept-Encoding: * Accept-Encoding: compress;q=0.5, gzip;q=1.0 Accept-Encoding: gzip;q=1.0, identity; q=0.5, *;q=0 클라이언트는 각 인코딩에 Q(quality)값을 매개변수로 더해 선호도를 나타낸다. 6. 전송 인코딩과 청크 인코딩 콘텐츠 인코딩은 콘텐츠 포맷과 긴밀하게 연관되어 있다. 전송 인코딩 또한 본문에 적용되는 가역적 변환이지만, 구조적인 이유 때문에 적용되는 것이며 콘텐츠의 포맷과는 독립적이다. 콘텐츠 인코딩 &amp; 전송 인코딩 콘텐츠 인코딩된 메시지는 단지 메시지의 엔터티 부분만 인코딩한다. 6.1 청크 인코딩 청크 인코딩은 메시지를 일정 크기의 청크 여럿으로 쪼갠다. 청크 인코딩을 이용하면 메시지를 보내기 전에 전체 크기를 알 필요가 없다. 청크 인코딩이 전송 인코딩의 한 형태이며 따라서 본문이 아닌 메시지의 속성이다. 청크 인코딩된 메시지의 구조 6.2 전송 인코딩 규칙 전송 인코딩의 집합은 반드시 chunked를 포함해야 한다. 청크 전송 인코딩이 사용되었다면, 메시지 본문에 적용된 마지막 전송 인코딩이 존재해야 한다. 청크 전송 인코딩은 반드시 메시지 본문에 한 번 이상 적용되어야 한다. 7. 검사기와 신선도 클라이언트는 처음에 리소스를 서버에게 달라고 요청보낸다. 클라이언트는 사본 리소스를 받아서 캐시한다. 클라이언트는 반드시 서버에게 최신 사본을 요청한다. 서버에서 문서가 변경되지 않았다면 클라이언트는 다시 받을 필요가 없다. 조건부 요청 클라이언트가 서버에게 자신이 갖고 잇는 버전을 말해주고 검사기를 사용해 자신의 사본 버전이 더 이상 유효하지 않을 때만 사본을 보내달라고 요청하는 것이다. 8. 범위 요청 HTTP 클라이언트는 받다가 실패한 엔터티를 일부 혹은 범위로 요청함으로써 다운로드를 중단된 시점에서 재개할 수 있다.","link":"/2020/01/05/http-guide-chap15/"},{"title":"HTTP 완벽가이드 16장","text":"16장 국제화 주요 국제화 이슈인 문자집합 인코딩과 언어 태그를 알아본다. 1. 국제적인 콘텐츠을 다루기 위해 필요한 HTTP 지원 HTTP에서 엔터티 본문이란 비트들로 가득 찬 상자에 불과하다. 국제 콘텐츠를 지원하기 위해, 서버는 클라이언트에게 각 문서의 문자와 언어를 알려줘서, 클라이언트가 문서를 이루고 있는 비트들을 올바르게 문자들로 풀어내고, 처리해서 사용자들에게 제공한다. 서버는 클라이언트에게 문서의 문자와 언어를 HTTP Content-Type charset 매개변수와 Content-Language 헤더를 통해 알려준다. 클라이언트는 서버에게 자신이 어떤 차셋 인코딩 알고리즘들과 언어들을 이해하며 무엇을 선호하는지 말해주기 위해 Accept-Charset과 Accept-Language 헤더를 보낸다. 2. 문자집합과 HTTP2.1 Charset은 글자를 비트로 변환하는 인코딩이다 HTTP Charset 값은 어떻게 엔터티 콘텐츠 비트들을 특정 문자 체계의 글자들로 바꾸는지 말해준다. Content-Type: text/html; charset=iso-8859-6 Content-Type 헤더는 수신자에게 콘텐츠가 HTML 파일임을 말해준다. charset 매개변수는 수신자에게 콘텐츠 비트들을 글자들로 디코딩하기 위해 iso-8859-6 아랍 문자집합 디코딩 기법을 사용하라고 말해준다. 3. 언어 태그와 HTTP 언어 태그는 언어에 이름을 붙이기 위한 짧고 표준화된 문자열이다. 3.1 Content-Language 헤더 엔터티가 어떤 언어 사용자를 대상으로 하고 있는지 서술한다. 텍스트 문서 이외의 오디오 클립, 동영상, 애플리케이션도 특정 언어 사용자를 대상으로 할 수 있다. 콘텐츠가 여러 언어를 대상으로 한다면, 언어들을 나열할 수 있다. Content-Language: mi, en 3.2 Accept-Language 헤더 웹 서버가 자원에 대해 여러 언어로 된 버전을 갖고 있다면, 사용자에게 선호하는 언어로 된 컨텐츠를 제공한다. 클라이언트는 자신이 이해 할 수 있는 콘텐츠를 요청하기 위해 Accept-Language와 Accept-Charset을 사용한다. 3.3 대소문자 구분 및 표현 모든 태그는 대소문자가 구분되지 않는다. 관용적으로 언어를 나타날때 소문자, 국가를 나타낼 때는 대문자를 사용한다. 4. 국제화된 URI 오늘날 URI는 국제화를 지원하지 않는다. 오늘날의 URI는 US-ASCII의 부분집합으로 구성되어 있다. 4.1 국제적 가독성 vs 의미 있는 문자들 문자집합에는 제한이 있기 때문에, URI는 비영어권 사람들도 쉽게 사용하고 기억할 수 있도록 설계되지는 못했다. URI 저자들은 리소스 식별자의 가독성과 고유 가능성의 보장이 중요하다고 여겼다. ASCII 문자들의 제한된 집합으로 이루어진 URI를 갖게 되었다. 4.2 URI에서 사용될 수 있는 문자들 US-ASCII 문자들의 부분집합은 예약된 문자들, 예약되지 않은 문자들, 이스케이프 문자들로 나뉜다. 예약되지 않음: [A-Za-z0-9] |”-“|”_”|”.”|”!”|”~”|”*”|”‘“|”(“|”)” 예약됨: “;”|”/“|”?”|”:”|”@”|”&amp;”|”=”|”+”|”$”|”,” 이스케이프: “%” 4.3 이스케이핑과 역이스케이핑(unescaping) 이스케이프는 예약된 문자난 다른 지원하지 않는 글자들을 안전하게 URI에 삽입할 수 있는 방법을 제공한다. 이스케이프는 퍼센트 글자 하나와 뒤이은 16진수 그자 둘로 이루어진 세 글자 문자열이다. 애플리케이션은 어떤 URI도 두 번 언이스케이핑 되지 않도록 해야 한다. 이스케이핑된 퍼센트 기호를 포함한 URI를 언이스케이핑하면 퍼센트 기호가 포함된 URI가 만들어진다. 잘못하여 한 번 더 언이스케이핑을 하게 되면 이스케이프의 일부처럼 처리되어 데이터의 손실을 유발한다. 5. 기타 고려사항5.1 헤더와 명세에 맞이 않는 데이터 HTTP 헤더는 반드시 US-ASCII 문자집합의 글자들로만 이루어져야 한다. HTTP 애플리케이션은 글자들을 처리하기 위해 운영체제와 리아브러리 루틴을 사용한다. 5.2 날짜 HTTP 명세는 올바른 GMT 날짜를 명확히 정의하지만, 모든 웹 서버와 클라이언트가 규칙을 따르지 않는다. 명세에 맞지 않는 날짜를 관대하게 받아들이고, 받아들이면서 충돌을 일으키지 말아야한다. 5.3 도메인 이름 국제화 문자를 포함하는 도메인 이름을 국제화 도메인 이름(Internationalizing Domain Name)이라 한다. 웹브라우저는 퓨니코드를 사용해 사용자가 입력한 다국어로 된 도메인 이름을 알파벳과 숫자 등으로 된 도메인 이름으로 변환한다.","link":"/2020/01/13/http-guide-chap16/"},{"title":"HTTP 완벽가이드 13장","text":"13장 다이제스트 인증 목표: 기본 인증과 호환되는 더 안전한 대체재로서의 다이제스트 인증을 알아본다. 1. 다이제스트 인증의 개선점특징 비밀번호를 절대로 네트워크를 통해 평문으로 전송하지 않는다. 인증 체결을 가로채서 재현하려는 악의적인 사람들을 처단한다. 구현하기에 따라서, 메시지 내용 위조를 막는것이 가능하다. 그 외의 잘 알려진 형태의 공격을 막는다. 1.1 비밀번호를 안전하게 지키기 위해 요약 사용하기 다이제스트 인증을 요약하면 “절대로 비밀번호를 네트워크를 통해 보내지 않는다” 이다. 클라이언트는 비밀번호를 비가역적으로 뒤섞은 지문(fingerprint) 혹은 요약(digest)를 보낸다. 1.2 단방향 요약 요약은 ‘정보 본문의 압축’이다. 요약은 단방향 함수로 동작하고, 무한 가지의 모든 입력 값들을 유한한 범위의 압축으로 변환한다. 만약 비밀번호를 모른다면 서버에게 보내줄 알맞은 요약을 추측하기 위해 많은 시간을 소모하게 된다. 요약은 비밀번호를 그대로 전송해야 할 필요성에서 해방시켜준다. 1.3 재전송 방지를 위한 난스(nonce) 사용 요약은 비밀번호 자체와 다름 없으므로 요약을 가로챈다면 요약을 서버로 재전송할 수 있다. 재전송을 막기 위해서 서버는 클라이언트에게 난스라고 불리는 특별한 증표를 넘겨준다. 난스는 약 1밀리초마다, 인증할때마다 바뀌게 된다. 1.4 다이제스트 인증 핸드 셰이크 서버는 난스 값을 계산한다. 서버는 난스를 WWW-Authenticate 인증요구 메시지에 담아, 알고리즘 목록과 함께 클라이언트에 보낸다. 클라이언트는 알고리즘을 선택하고 비밀번호와 그 외 데이터에 대한 요약을 계산한다. 클라이언트는 Authorization 메시지에 요약을 담아 서버에게 돌려준다. 서버는 요약, 선택한 알고리즘, 그 외 보조 데이터들을 받고, 클라이언트가 했던 그대로 요약을 계산한다. 서버는 자신이 계산한 요약과 네트워크로 전송되어 온 요약이 서로 같은지 확인한다. 2. 보호 수준(Quality of Protection) 향상 qop 필드는 클라이언트와 서버가 어떤 보호 기법을 어느 정도 수준으로 사용할 것인지 협상할 수 있게 해준다. 2.1 메시지 무결성 보호 무결성 보호가 적용되었을 때 계산되는 엔터티 본문은, 메시지 본문의 해시가 아닌 엔터티 본문의 해시이다. 송신자에 의해 어떠한 전송 인코딩이 적용되기도 전에 먼저 계산되고 그 후 수신자에 의해 제거된다. 2.2 다이제스트 인증 헤더 기본, 다이제스트 인증은 WWW-Authentication 헤더에 담겨 전달되는 인증요구와, Authentication 헤더에 담겨 전달되는 인기 응답을 포함한다. 다이제스트는 Authentication-Info 헤더를 추가했다. 3단계 핸드셰이크를 완성하고 다음번 사용할 난스를 전달하기 위해 인증 성공 후에 전송된다. 3. 다이제스트 인증 작업시 고려할것들 3.1 다중 인증요구 서버는 한 리소스에 대해 여러 인증을 요구할 수 있다. 다양한 인증 옵션을 제공하는 경우, ‘가장 허약한 부분‘에 대한 보안우려가 있다는 것이 명확하다. 3.2 오류처리 지시자나 그 값이 적절하지 않거나 요구된 지시자가 빠져 있으면, 응답은 400 Bad Request이다. 인증 서버는 uri 지시자가 가리키는 리소스가 요청줄에 명시된 리소스와 같음을 확인해야 한다. 반복된 실패에 대해서는 따로 기록해 두는 것이 좋다. 3.3 보호 공간(Protection Space) 영역 값은 접근한 서버의 루트 URL과 결합되어 보호 공간을 정의한다. 영역 값은 원 서버에 의해 할당되는 문자열이며 인증 제도에 추가적인 의미를 더한다. 보호 공간은 어떤 자격이 자동으로 적용되는 영역을 정한다. 3.4 URI 다시 쓰기 프락시는 가리키는 리소스의 변경 없이 구문만 고쳐서 URI를 다시 쓰기도 한다. 호스트 명은 정규화되거나 IP 주소로 대체된다. 문자들은 % escape 형식으로 대체될 수 있다. 서버로부터 가져오는 리소스에 영향을 주지 않는, 타입에 대한 추가 속성이 URI의 끝에 붙거나 중간에 삽입될 수 있다. 3.5 캐시Authorization 헤더를 포함한 요청과 그에 대한 응답을 받은 경우, 두 Cache-Control 지시자 중 하나가 응답에 존재하지 않는 한 다른 요청에 대해 응답을 반환해서는 안된다. 4. 보안에 대한 고려사항4.1 헤더 부당 변경헤더 부당 변경에 대해 안전한 시스템을 제공하기 위해서, 양 종단 암호화나 헤더에 대한 디지털 서명이 필요하다. 4.2 재전송 공격 폼 데이터를 전송할 때 이전에 사용했던 자격을 재사용해도 문제없이 동작한다면, 큰 문제가 생기게 된다. 재전송 공격을 완전히 피하기 위해서는 매 트랜잭션마다 유일한 난스 값을 사용하는 것이다. 서버는 매 트랜잭션마다 난스와 함께 타임아웃 값을 발급한다. 4.3 다중 인증 메커니즘 클라이언트에게 항상 가장 강력한 인증제도를 선택하도록 한다. 가장 강력한 인증 제도만을 유지하는 프락시 서버를 사용한다. 4.4 사전 공격 전형적인 비밀번호 추측 공격이다. 비밀번호 만료 정책이 없고, 충분한 시간이 있고, 비밀번호를 크래킹할 비용을 치를 수 있다면, 비밀번호를 쉽게 수집할 수 있다. 크래킹하기 어렵도록 복잡한 비밀번호를 사용하고 괜찮은 비밀번호 만료 정책을 사용하는 것이 좋다. 4.5 악의적인 프락시와 중간자 공격 프락시중 하나가 악의적이거나 보안이 허술하다면 클라이언트는 중간자 공격에 취약한 상태가 될 수 있다. 프락시는 보통 정교한 프로그래밍 인터페이스를 제공하므로 그러한 프락시들을 이용하는 플러그인을 이용하여 트래픽을 가로채 수정하는 것이 가능하다. 이 문제를 해결하기에는 한계가 있으므로, 클라이언트가 가능한 가장 강력한 인증을 선택하도록 설정한다. 4.6 선택 평문 공격 보안이 허술하거나 악의적인 프락시가 트래픽 중간에 끼어든다면, 클라이언트가 응답 계산을 하기 위한 난스를 제공 할 수 있다. 응답을 계산하기 위해 알려진 키를 사용하는 것은 응답의 암호 해독을 쉽게 한다. 클라이언트가 서버에서 제공된 난스 대신 선택적인 c난스 지시자를 사용하여 응답을 생성할 수 있도록 설정하는 것이 좋다. 4.7 비밀번호 저장 다이제스트 인증 비밀번호 파일이 유출되면 영역의 모든 문서는 공격자에게 노출된다. 비밀번호 파일이 평문으로 된 비밀번호를 포함하고 있다고 생각하고 안전하게 보호한다. 영역 이름이 유일함을 보장한다.","link":"/2019/11/24/http-guide-chap13/"},{"title":"HTTP 완벽가이드 18장","text":"18장 웹 호스팅 웹 호스팅의 가장 중요한 속성들과 그것들이 어떻게 HTTP 애플리케이션과 상호작용하는지 알아본다. 1. 호스팅 서비스 전문적으로 서버실을 짓고 도메인을 등록하고 네트워크 대역폭을 구매하는 기술과 시간을 가진 업체들이 있다. 물리적인 장비 관리에서 고객이 직접 콘텐츠를 제공할 수 있는 총체적인 웹 호스팅까지 다양한 종류의 서비스들이 있다. 2. 가상 호스팅 웹 호스팅 업자는 컴퓨터 한 대를 여러 고객이 공유하게 해서 저렴한 웹 호스팅 서비스를 제공하는데, 이를 공유 호스팅 또는 가상 호스팅이라 부른다. 가상 호스팅은 비용, 공간, 관리에 이점이 있다. 호스팅 업자는 복제 서버 더미(서버 팜)를 만들고 서버 팜에 부하를 분산할 수 있다. 수많은 가상 웹사이트를 호스팅 하므로 관리자는 훨씬 편해진다. 2.1 호스트 정보가 없는 가상 서버 요청 HTTP/1.0 명세는 공용 웹 서버가 호스팅하고 있는 가상 웹 사이트에 누가 접근하고 있는지 식별하는 기능을 제공하지 않는다. 여러 개의 요청이 완전히 다른 문서를 요청을 하더라도, 요청 자체가 똑같이 생겼다. HTTP 대리 서버(리버스 프락시)와 인터셉트 프락시는 어떤 사이트를 요청하는지에 관한 정보가 필요하다. 2.2 가상 호스팅 동작하게 하기URL 경로를 통한 가상 호스팅 서버가 어떤 사이트를 요청하는 것인지 알 수 있게 URL에 특별한 경로 컴포넌트를 추가한다. 경로에 있는 정보를 통해 해당 URL을 분석한다. GET joes/index.html GET mary/index.html 일반적으로, URL 기반의 가상 호스팅은 좋지 않은 방법이다. 포트 번호를 통한 가상 호스팅 각 사이트에 다른 포트번호를 할당하여, 분리된 웹 서버의 인스턴스 요청 처리를 한다. 사용자는 URL에 비표준 포트를 쓰지 않고서도 리소스를 찾길 원하는 문제가 생긴다. IP 주소를 통한 가상 호스팅 각 가상 웹 사이트에 유일한 IP 주소를 한 개 이상 부여한다. 모든 가상 서버의 IP 주소는 같은 공용 서버에 연결되어 있다. 문제점들 컴퓨터 시스템이 연결할 수 있는 장비의 IP의 개수에 제한이 있다. 가상 사이트를 많이 가지고 있는 호스팅 업자는 호스팅 하는 모든 웹 사이트에 할당할 가상 IP 주소를 충분히 얻지 못할 수 있다. 부하 균형의 구조상, 용량을 늘리기 위해 서버를 복제하면서, 각 복제된 서버에 IP 주소를 부여해야 하므로 IP 주소는 복제 서버의 개수만큼 더 필요하게 된다. Host 헤더를 통한 가상 호스팅 모든 요청에 호스트명을 Host 확장 헤더에 기술해서 전달한다. 2.3 HTTP/1.1 Host 헤더 가상 서버는 매우 흔하기 때문에 대부분의 HTTP 클라이언트가 HTTP/1.1과 호환되지 않더라도, Host헤더는 구현한다. Host = &quot;Host&quot; &quot;:&quot; 호스트[ &quot;:&quot; 포트 ] 3. 안정적인 웹 사이트 만들기3.1 미러링 된 서버 팜 서버 팜은 서로 대신할 수 있고 식별할 수 있게 설정된 웹 서버들의 집합이다. 서버팜의 서버에 있는 콘텐츠들은 한 곳에 문제가 생기면 다른 한 곳에서 대신 전달할 수 있게 미러링 할 수 있다. HTTP 리다이렉션 콘텐츠에 대한 URL은 마스터 서버의 IP를 가리키고, 마스터 서버는 요청을 받는 즉시 복제 서버로 리다이렉트시킨다. DNS 리다이렉션 콘텐츠의 URL은 여러 개의 IP 주소를 가리킬 수 있고, DNS 서버는 클라이언트에게 전송할 IP 주소를 선택할 수 있다. 3.2 콘텐츠 분산 네트워크 콘텐츠 분산 네트워크(CDN)는 특정 콘텐츠의 분산을 목적으로 하는 단순한 네트워크이다. 3.3 CDN의 대리 캐시 대리 서버는 콘텐츠에 대한 요청을 받는다. 원 서버 집합을 대신해 요청을 받는다. 미러링 된 서버와의 차이점 수요에 따라서 동작한다. 원 서버의 전체 콘텐츠를 복사하지 않는다. 클라이언트가 요청하는 콘텐츠만 저장한다. 3.4 CDN의 프락시 캐시 대리 서버를 사용하면, 프락시 캐시의 콘텐츠는 요청이 있을 때만 저장되고 원본 서버 콘텐츠를 정확히 복제한다는 보장이 없다. 요청이 있을 때만 저장하는 프락시 캐시는 스위치 혹은 라우터가 중간에서 웹 트래픽을 가로채 처리한다. 4. 웹 사이트 빠르게 만들기 콘텐츠를 분산시키면, 그 콘텐츠를 사용자에게 더 가깝게 만들어 주므로 콘텐츠를 서버에서 클라이언트로 전송하는 시간이 단축된다. 콘텐츠를 인코딩하는것 5. WebDav 웹 분산 저작과 버저닝(Web Distributed Authoring and Versioning) 공동 저작에 적합한 플랫폼을 제공하려고 HTTP를 확장하는데 집중한다.","link":"/2020/02/03/http-guide-chap18/"},{"title":"HTTP 완벽가이드 19장","text":"19장 배포 시스템1. WebDav 웹 분산 저작과 버저닝(Web Distributed Authoring and Versioning) 공동 저작에 적합한 플랫폼을 제공하려고 HTTP를 확장하는데 집중한다. 2. WebDav와 공동저작2.1 WebDav와 XML WebDav의 메서드는 요청과 응답 관련 정보를 모두 잘 다루어야함 WebDav는 여러개의 리소스나 계층 관계에 있는 리소스들에 대해 정보를 선택적으로 헤더에 기술하기 위해서 XML포맷을 지원한다. 2.2 WebDav헤더 WebDav는 새로운 메서드들의 기능을 넓혀주는 여러 HTTP메서드를 도입했다 모든 리소스는 OPTIONS 요청에 대한 응답에 이 헤더를 포함해야한다. Depth는 계층 구조로 분류된 리소스 사용에 용이하다. Destination은 COPY나 MOVE 메서드가 목적지 URI를 식별하는데 사용한다. 2.3 WebDav 잠금과 덮어쓰기 방지 WebDav는 잠금이라는 개념을 지원한다 잠금은 완벽하지 않으므로 버저닝과 메시징을 지원해야한다 잠금을 수행하기 위해서는 다이제스트 인증을 요구한다 2.4 속성과 META 데이터 속성에는 저작자의 이름, 수정한 날자, 내용 등급 등 리소스의 정보를 기술한다. 속성의 발견과 수정을 지원하기 위해, WebDav는 PROFIND와 PROPPATCH라는 새로운 메소드를 추가한다. 2.5 콜렉션과 이름공간 관리 콜렉션은 리소들의 논리적 혹은 물리적 그룹이다. 파일시스템의 디렉터리 같이 다른 리소스들의 컨테이너처럼 동작한다. WebDav는 XML 이름 공간 메커니즘을 사용한다. 이름공간 파티션들은 충돌이 생기지 않고 명확한 구조적 제어기능을 제공한다. 2.6 MKCOL 메서드 클라이언트가 지정된 URL에 해당하는 콜렉션을 서버에 생성하게 한다. WebDav 프로토콜은 새로운 메서드를 정의하는 방식을 사용한다. 2.7 DELETE 메서드 디렉터리를 지우기 위해서는 Depth 헤더를 필요로한다. Depth가 없다면, DELETE 메서드는 Depth 헤더가 무한으로 설정되어 있다고 가정한다. 디렉터리와 그 하위에 있는 모든 디렉터리가 지워진다. 2.8 COPY와 MOVE 메서드 COPY 메서드는 리소스에 GET 요청을 보내고, 리소스를 다운 받은 다음, PUT 요청과 함께 서버에 리소스를 다시 올리는 것이다. MOVE는 DELETE메소드를 포함한 COPY와 비슷하게 동작한다. MOVE 메서드는 원본지 URL을 목적지에 복사하고, 새로 생성된 URI의 무결성을 검사하고, 원본을 지운다.","link":"/2020/02/10/http-guide-chap19/"},{"title":"HTTP 완벽가이드 2장","text":"2장 URL과 리소스2.1 인터넷의 리소스 탐색하기URL은 브라우저가 정보를 찾는데 필요한 리소스의 위치를 가리킨다. ex) http://www.joes-hardware.com/seasonal/index-fall.html 이라는 URL 을 불러온다고 하자. http는 URL의 스킴으로 웹 클라이언트가 리소스에 어떻게 접근하는지 알려준다. www.joes-hardware.com은 서버 위치로 웹 클라이언트가 리소스가 어디에 호스팅 되어 있는지 알려준다. /seasonal/index-fall.html은 리소스의 경로로 서버에 존재하는 로컬 리소스들 중에서 요청받은 리소스가 무엇인지 알려준다. URL을 사용하면 리소스를 일관된 방식으로 지칭할 수 있으며, 대부분의 URL은 “스킴://서버위치/경로“ 구조로 이루어져있다. 2.2 URL 문법대부분의 URL은 일반 URL 문법을 따르며, 서로 다른 URL 스킴도 형태와 문법 면에서 매우 유사하다. 스킴의 문법은 일반적으로 9개로 나뉜다. &lt;스킴&gt;://&lt;사용자 이름&gt;:&lt;비밀번호&gt;@&lt;호스트&gt;:&lt;포트&gt;/&lt;경로&gt;;&lt;파라미터&gt;?&lt;질의&gt;#&lt;프래그먼트&gt; 2.2.1 스킴: 사용할 프로토콜스킴은 주어진 리소스에 어떻게 접근하는지 알려주는 중요한 정보로, 어떤 프로토콜을 사용하여 리소스를 요청해야하는지 알려준다. 2.2.2 호스트와 포트URL의 호스트와 포트 컴포넌트가 존재한다. 호스트 컴포넌트: 접근하려고 하는 리소스를 가지고 있는 인터넷상의 호스트 장비를 가리킨다. 포트 컴포넌트: 서버가 열어놓은 네트워크 포트를 가리킨다. 2.2.3 사용자 이름과 비밀번호많은 서버가 자신이 가지고 있는 데이터를 제공하기 전에 사용자 이름과 비밀번호를 요구한다. ftp://ftp.prep.ai.mit.edu/pub/gnu → 표준 스킴, 호스트, 경로만 존재한다. ftp://anonymous@ftp.prep.ai.mit.edu/pub/gnu → 기본 사용자 이름 값은 ‘anonymous’, 비밀번호는 브라우저마다 가지고 있는 기본값을 사용한다. ftp://anonymous:my_passwd@ftp.prep.ai.mit.edu/pub/gnu → 사용자 이름 ‘anonymous’ 비밀본호 ‘my_passwd’를 ‘:’문자로 구분하여 사용한다. ‘@’는 URL에서 사용자 이름과 비밀번호 컴포넌트를 분리한다. 2.2.4 경로URL의 경로 컴포넌트는 리소스가 서버의 어디에 있는지 알려준다. http://www.joes-hardware.com:80/seasonal/index-fall.html ‘/‘ 문자를 기준으로 경로조각으로 나뉘며, 각각의 경로조각은 자체만의 파라미터 컴포넌트를 가질 수 있다. 2.2.5 파라미터애플리케이션이 서버에 정확한 요청을 하기 위해 필요한 입력 파라미터를 받는데 사용한다. URL의 파라미터 컴포넌트는 이름=값 쌍의 리스트로 URL 나머지로 부터 ‘;’ 문자로 구분하여 URL에 기술한다. 리소스에 접근하는데 필요한 어떤 추가 정보든 전달할 수 있다. ftp://prep.ai.mit.edu/pub/gnu;type=d 이름은 ‘type’이고, 값은 ‘d’인 type=d라는 단 한 개의 파라미터를 전달한다. 2.2.6 질의 문자열데이터베이스 같은 서비스들은 요청받을 리소스 형식의 범위를 좁히기 위해서 질문이나 질의를 받을 수 있다. http://www.joes-hardware.com/inventory-check.cgi?item=12731 위 URL은 아이템 번호가 ‘12731’의 재고가 있는지 확인하기 위해서 사용된다. ‘?’ 문자에 이어서 오는 값을 질의 컴포넌트라고 한다. ‘&amp;’문자로 나뉜 ‘이름=값‘ 쌍 형식의 질의 문자열을 많이 사용한다. 2.2.7 프래그먼트리소스의 특정 부분을 가리킬 수 있도록, URL은 리소스 내의 조각을 가리킬 수 있는 프래그먼트 컴포넌트를 제공한다. 프래그먼트는 URL의 오른쪽에 # 문자에 이어서 온다. http://www.joes-hardware.com/tools.html#drills drills라는 프래그먼트는 /tools.html 웹페이지의 일부를 가리킨다. HTTP서버는 객체 일부가 아닌 전체만 다루기 때문에, 클라이언트는 서버에 프래그먼트를 보내지 않는다. 브라우저가 서버로부터 리소스를 내려받은 후에 프래그먼트를 사용해서 보고자 하는 리소스의 화면을 보여준다. 2.3 단축 URL웹 클라이언트는 몇몇 단축 URL을 인식하고 사용한다. 상대 URL은 리소스 안에 있는 리소스를 간결하게 기술하는데 사용할 수 있다. 2.3.1. 상대 URLURL은 상대 URL과 절대 URL 두가지로 나뉜다. 상대 URL 리소스에 접근하는데 필요한 모든 정보를 가지고 있지 않다. URL을 짥게 표시하는 방식이다. HTML 작성자는 URL에 스킴과 호스트 그리고 다른 컴포넌트들을 모두 입력하지 않아도 된다. 절대 URL 리소스에 접근하는데 필요한 모든 정보를 가지고 있다. URL 확장사용자가 URL을 입력한 다음이나 입력하고 있는 동안에 자동으로 URL을 확장한다. 호스트 명 확장 ‘yahoo’를 주소창에 입력한다면, 브라우저는 호스트 명에 자동으로 ‘www.’과 ‘.com’을 붙여서 ‘www.yahoo.com'을 만든다. 히스토리 확장 URL 입력하는 시간을 줄이고자, 과거에 사용자가 방문했던 URL의 기록을 저장해 놓는 것이다. URL의 시작부분을 입력하면 자동으로 전체 URL을 보여준다. 2.4 안전하지 않은 문자 프로토콜이 데이터를 전송하기 위해서 서로 다른 장치를 가지고 있기 때문에, 어떤 인터넷 프로토콜을 통해서든 안전하게 전송될 수 있도록 URL을 설계하는 것이 중요하다. 안전한 전송이란, 정보가 유실될 위험 없이 URL을 전송할 수 있다는 것을 의미한다. 이스케이프라는 기능을 추가하여, URL에 있는 안전하지 않는 문자들을 표현할 수 있도록 인코딩 방식을 사용하여 이동성과 완성도를 높였다.","link":"/2019/08/11/http-guide-chap2/"},{"title":"HTTP 완벽가이드 17장","text":"17장 내용 협상과 트랜스 코딩1. 내용 협상 기법 서버에 있는 페이지들 중 어떤 것이 클라이언트에게 맞는지 판단하는 세 가지 다른 방법이 있다. 클라이언트 주도 협상, 서버 주도 협상, 투명한 협상에 대해서 알아본다. 2. 클라이언트 주도 협상 서버에게 가장 쉬운 방법은 서버가 클라이언트의 요청을 받았을 때 가능한 페이지의 목록을 응답을 돌려주어 클라이언트가 보고 싶은 것을 선택하게 하는 것이다. 단점 각 페이지에 두 번의 요청이 필요하다.(목록 &amp; 사본) 느리고 지루하다. 서버는 클라이언트에게 여러가지 버전에 대한 링크와 설명이 담긴 HTML 페이지를 돌려준다. 300Multiple Choices 응답 코드로 HTTP/1.1응답을 돌려준다. 단점 대기시간이 증가되고, 페이지당 여러 번의 요청이 필요하다. 3. 서버 주도 협상 클라이언트가 서버가 결정을 하도록 요청 헤더에 정보를 삽입한다. 내용 협상 헤더 → 서버는 클라이언트의 Accept 관련 헤더들을 보고 그에 알맞은 응답을 돌려 준다. 이외의 다른 헤더 → ex) 서버는 클라이언트의 User-Agent헤더에 기반하여 응답을 돌려준다. 3.1 내용 협상 헤더 HTTP 헤더들을 이용해서 자신의 선호 정보를 보낸다. Accept: 서버가 어떤 미디어 타입으로 보내도 되는지 알려준다. Accept-Language: 서버가 어떤 언어로 보내도 되는지 알려준다. Accept-Charset: 서버가 어떤 차셋으로 보내도 되는지 알려준다. Accept-Encoding: 서버가 어떤 인코딩으로 보내도 되는지 알려준다. HTTP는 상태가 없는 프로토콜이기 때문에 클라이언트는 자신의 선호 정보를 매 요청마다 보내야한다. 3.2 내용 협상 헤더의 품질값 HTTP 프로토콜은 클라이언트가 각 선호의 카테고리마다 여러 선택 가능한 항목을 선호도와 함께 나열할 수 있도록 품질값을 정의하였다. q값은 0.0부터 1.0까지의 값을 가진다.(커질수록 높은 선호도) 3.3 그 외의 헤더들에 의해 결정 서버는 User-Agent와 같은 헤더들을 이용해 알맞은 요청을 만들어내려고 시도할 수 있다. 서버가 웹브라우저에서 자바스크립트를 지원하지 않는다는 것을 알고 있다면, 자바스크립트를 포함하지 않은 페이지를 돌려줄 수 있다. 4. 투명협상 클라이언트 입장에서 협상하는 중개자 프락시를 둔다. 메시지 교환을 최소화 하며 서버 주도 협상으로 인한 부하를 서버에서 제거한다. 4.1 캐시와 얼터네이트(alternate) 캐시는 클라이언트에게 올바르게 응답을 돌려주기 위해, 서버가 응답을 돌려줄 때 사용했던 로직을 상당부분 사용한다. 캐시는 반드시 모든 요청을 서버에게 전달하고 모든 응답을 저장해야 한다. 캐시는 같은 URL에 대해 두 개의 다른 문서를 갖게 된다. 이 다른 번전은 배리언트(variant)나 얼터네이트(alternate)라고 불린다. 4.2 Vary 헤더 HTTP Vary 응답 헤더는 클라이언트 요청 헤더 모두를 나열한다. 캐시가 문서를 클라이언트에게 제공해 주기 전에, 캐시는 반드시 캐시된 응답 안에 서버가 보낸 Vary 헤더가 있는지 확인한다. Vary 헤더가 존재한다면, Vary 헤더가 명시하고 있는 헤더들은 새 요청과 오래되고 캐시된 요청의 값이 맞아야 한다. 5. 트랜스코딩 서버가 클라이언트의 요구에 맞는 문서를 가지고 있지 않다면, 서버는 기존의 문서를 클라이언트가 사용할 수 있는 무언가로 변환 할 수 있다. 이 옵션을 트랜스코딩이라 한다. 5.1 포맷 변환 데이터를 클라이언트가 볼 수 있도록 한 포맷에서 다른 포맷으로 변환하는 것이다. 포맷 변환은 내용 협상 헤더에 의해 주도된다. 콘텐츠를 특정 접근 장치에서 볼 수 있도록 하는 것이다. 5.2 정보 합성(information synthesis) 각 절의 제목에 기반한 문서의 개요 생성이나 페이지에서 광고 및 로고 제거와 같은 예가 있다. 웹페이지 디렉토리와 같은 자동화된 웹페이지 분류 시스템에 의해 종종 사용된다. 5.3 콘텐츠 주입 자동 광고 생성, 사용자 추적 시스템과 같은 예가 있다. 특정 사용자를 대상으로 자동으로 광고를 삽입한다. 어떻게 페이지가 보여지고 사용자가 웹을 서핑하는 거에 따라 동적으로 콘텐츠를 삽입한다. 5.4 트랜스코딩 vs 정적으로 미리 생성 트랜스코딩의 대안으로는 웹 서버에서 웹페이지의 여러 사본을 만드는 것이다. 페이지의 작은 변화에 따라 페이지의 수정이 필요하다. 모든 버전을 저장하기 위해 더 많은 공간이 필요하다. 페이지를 관리하고 올바른 페이지를 노출 시키도록 웹 서버를 프로그래밍하기 어려워진다. 광고 삽입과 같은 트랜스코딩은 요청한 사용자에게 달려있기 때문에 정적인 방법으로는 수행될 수 없다. 루트 페이지를 필요할 때마다 변환하는 것이 좋다.","link":"/2020/01/19/http-guide-chap17/"},{"title":"HTTP 완벽가이드 20장","text":"20장 리다이렉션과 부하 균형 리다이렉션 기법들과 그것들이 어떻게 동작하며 어떤 부하 균형 능력을 갖고 있는지 알아본다 1. 왜 리다이렉트인가?HTTP 애플리케이션이 원하는것 신뢰할 수 있는 HTTP 트랜잭션의 수행 지연 최소화 네트워크 대역폭 절약 리다이렉션 최적의분산된 콘텐츠를 찾는 것을 도와주는 기법의 집합 2. 리다이렉트 할 곳 서버, 프락시, 캐시, 게이트웨이는 클라이언트에게 있어서 HTTP 요청을 보내고 그것을 처리하므로 서버라고 할 수 있다. 서버로의 리다이렉트는 휘발유를 찾는 운전 기사를 가장 가까운 주유소로 보내는 것이다. 프락시로의 리다이렉트는 진입로의 트래픽을 근처에 있는 지름길로 빨아들이는 것과 같다. 3. 리다이렉션 프로토콜의 개요 HTTP 메시지를 웹 서버로 가급적 빨리 보내는 것이 리다이렉션의 목표다. HTTP 메시지는 HTTP 애플리케이션과 라우팅 장치에 영향을 받는다. 메시지를 서버로 리다이렉트하기 위한 여러 방법들이 존재한다. 4. 일반적인 리다이렉션 방법4.1 HTTP 리다이렉션 요청을 처리하는 서버는 가용한 것들 중 부하가 가장 적은 콘텐츠 서버를 찾아서 브라우저의 요청을 그 서버로 리다이렉트 한다. 리다이렉트를 하느 서버가 클라이언트의 아이피 주소를 아는 것은 좀 더 정보에 근거해 선택하므로 장점이다. 단점 어떤 서버로 리다이렉트할지 경정하려면 원 서버는 상당히 많은 처리를 해야 한다. 페이지에 접근할 때마다 두 번의 왕복이 필요하므로 사용자가 더 오래 기다리게 된다. 리다이렉트 서버가 고장나면, 사이트도 고장난다. 4.2 DNS 리다이렉션 클라이언트가 웹사이트에 접근하려고 시도할 때마다, 도메인 이름은 반드시 아이피 주소로 분석되어야 한다. DNS는 하나의 도메인에 여러 아이피 주소가 결부되는 것을 허용한다. DNS 분석자는 여러 아이피 주소를 반환하도록 결정하는 방법은 다양하다. DNS 결정 알고리즘은 라운드 로빈이 가장 쉽다. DNS 라운드 로빈 웹 서버 팜 전체에 대한 부하의 균형을 유지하기 위해 DNS 호스트명 분석 기능을 사용한다. DNS 클라이언트는 다중 주소 집합의 첫 번째 주소를 사용한다. DNS 서버는 룩업이 끝났을 때마다 주소를 순환시킨다. DNS 캐싱의 효과 DNS 룩업은 애플리케이션, 운영체제 등 DNS 서버에 의해 재사용 되어 비용을 줄이게 된다. 클라이언트의 수가 어느정도 이상만 된다면, 부하는 모든 서버에 잘 분산된다. 4.3 임의 캐스팅 어드레싱 여러개의 흩어진 웹 서버들은 정확히 같은 아이피 주소를 갖고 클라이언트의 요청을 클라이언트에서 가장 가까운 서버로 보내주기 위해 백본 라우터의 최단거리 라우팅 능력에 의지한다. 백본 라우터가 임의 캐스트 주소를 목적지로 하는 패킷을 받았을때, 그 아이피 주소를 받아들일 수 잇는 가장 가까운 라우터를 찾는다. 서버는 반드시 라우터의 언어로 말해야하고 라우터는 일어날 수 있 는 주소 충돌을 반드시 다룰수 있어야 한다. 4.4 아이피 맥 포워딩 HTTP 메시지는 주소가 붙은 데이터 패킷의 형태로 보내진다. 각 패킷은 출발지와 목적지의 아이피 주소와 TCP 포트 번호로 이루어진 레이어4 주소를 갖는다. 레이어2의 역할은 들어오는 특정 맥(MAC) 주소의 패킷을 받아서 나가는 특정 맥 주소로 포워딩한다. 4.5 아이피 주소 포워딩 스위치나 레이어4를 이해하는 장비는 들어오는 패킷에 대해 TCP/IP 어드레싱을 검증하고 패킷을 목적지 맥 주소가 아니라 목적지 아이피 주소의 변경에 따라 라우팅한다. 목적지 서버가 한 홉 거리에 있을 필요가 없다. 스위치는 반드시 그 커넥션을 통해 클라이언트에게 응답을 돌려줘야 한다. 5. 프락시 리다이렉션 방법5.1 명시적 브라우저 설정 대부분의 브라우저에는 프락시 서버에 접촉하기 위한 프락시 이름, 아이피 주소, 포트번호를 설정하는 메뉴가 존재한다. 사용자의 설정에 따라 모든 요청에 대해 프락시와 접촉한다. 단점 만약 프락시가 다운되었거나 브라우저가 잘못 설정되었다면, 사용자는 접속 문제에 마주하게 된다. 네트워크 아키텍처를 변경했을 때 그 변경사항을 모든 최종사용자에게 전파하는것이 어렵다. 5.2 프락시 자동 설정(Proxy Auto-configuration, PAC) 브라우저가 동적으로 자신을 설정할 수 있게 하는 것이다. PAC는 브라우저들이 URL별로 접촉해야 할 프락시를 지정한 PAC 파일이라 불리는 특별한 파일을 찾도록 하는것이다. 브라우저는 반드시 PAC파일을 얻기 위해 지정된 서버에 접촉하도록 설정되어 있다. 브라우저는 재시작 할 때마다 PAC 파일을 가져온다. PAC 파일은 다음의 함수를 반드시 정의해야하는 자바스크립트 파일이다. function FindProxyForURL(url, host) 5.3 웹 프락시 자동발견 프로토콜(Web Proxy Autodiscovery Protocol) 웹브라우저가 근처의 프락시를 찾아내어 사용할 수 있게 해주는 방법을 제공해 준다. 6. 캐시 리다이렉션 방법 신뢰성이 높고, 고성능, 콘텐츠 지각 디스패칭이 가능하게 하여 복잡한 방법이다. 6.1 WCCP 리다이렉션 캐시 조직 프로토콜(WCCP)는 라우터들과 캐시들 사이의 대화를 관리하여 라우터가 캐시를 검사하고, 특정 종류의 트래픽을 특정 캐시로 보낼 수 있게 해준다. WCCP 서비스 그룹을 구성하고, 어떤 트래픽이 어디로 어떻게 보내지는지, 서비스 그룹에서 부하가 캐시들 사이에서 어떻게 분산되어야 하는지 명시한다. HTTP 요청이 서비스 그룹의 라우터에 도착한다면, 라우터는 그 요청을 처리하기 위해 서비스 그룹의 캐시 중 하나를 선택한다. 7. 캐시 배열 라우팅 프로토콜 부하를 분산하기 위해 사용하는 프락시 서버를 여러대로 늘리는 것이다. CARP는 프락시 서버의 배열이 클라이언트의 시점에서는 마치 하나의 논리적인 캐시처럼 보이도록 관리해주는 표준이다. 각 구성요소 서버가 전체 캐시된 문서의 일부만 갖고 있는 하나의 큰 서버처럼 동작한다. 하나의 웹 객체는 하나의 프락시 서버에만 속하기 때문에, 프락시 서버 각각을 폴링하지 않고도 한 번의 검색으로 그 객체의 위치를 결정할 수 있다. 8. 하이퍼텍스트 캐싱 프로토콜 HTCP는 형제들이 URL과 모든 요청 및 응답 헤더를 사용하여 서로에게 문서의 존재 여부에 대한 질의를 할수 있도록 해줌으로써 적중이 아님에도 적중으로 잘못 처리될 확률을 줄인다. 캐시들이 서로의 캐시 안에 있는 선택된 문서의 추가 및 삭제를 모니터링하고 요청할 수 있게 해준다. 근처 캐시가 문서를 갖고 있다면, 요청 캐시는 그 캐시에 HTTP 커넥션은 열고 그 문서를 가져 온다.","link":"/2020/02/10/http-guide-chap20/"},{"title":"HTTP 완벽가이드 21장","text":"21장 로깅과 사용 추적 로깅을 알아보고, 어떤 HTTP 트랜잭션 정보를 기록하고, 로그 포맷에는 어떤것들이 있는지 알아본다. 1. 로그란 무엇인가? 대체적으로 로깅을 하는 이유? 서버나 프락시의 문제를 찾기 위해서 웹 사이트 접근 통계를 내기위해서 별 연관성이 없고 다시 볼 일도 없는 데이터만 로깅한다. 보통은 트랜잭션의 기본적인 항목들만 로깅한다. HTTP 메서드 클라이언트와 서버의 HTTP 버전 요청받은 리소스의 URL 응답의 HTTP 상태 코드 요청과 응답 메시지의 크기 트랜잭션이 일어난 시간 Referer와 User-Agent 헤더 값 2. 로그 포맷 상용 혹은 오픈 소스 HTTP 애플리케이션은 대부분, 표준 로그 포맷을 한 개 이상 지원한다. 애플리케이션이 더 많은 표준 포맷을 지원하고 관리자가 사용할 수록 얻을 수 있는 이점이 많다. 2.1 일반 로그 포맷(Common Log Format) 가장 일반적인 포맷이며, 많은 서버들이 기본으로 사용한다. 필드 설명 remotehost 요청한 컴퓨터의 호스트 명 혹은 IP주소 username ident 검색을 수행했다면, 인증된 요청자의 사용자 이름 auth-username 인증을 수행했다면, 인증된 요청자의 이름 teimstamp 요청 날짜와 시간 request-line HTTP 요청의 행을 그대로 기술 response-code 응답으로 보내는 HTTP 상태 코드 response-size 응답 엔터티의 Content-Length, 아무런 엔터티를 반환하지 않으면 값이 0이 된다. 일반 로그 포맷 엔트리의 몇가지 예 209.1.32.44 - - [03/Feb/2020:14:15:00 -0400] &quot;GET / HTTP/1.0&quot; 200 1024 bebiangel.github.io - dg [03/Feb/2020:14:15:00 -0400] &quot;GET / HTTP/1.0&quot; 200 477 bebiangel.github.io - dg [03/Feb/2020:14:15:00 -0400] &quot;GET /foo HTTP/1.0&quot; 404 0 필드 엔트리1 엔트리2 엔트리3 remotehost 209.1.32.44 bebiangel.github.io bebiangel.github.io username 없음 없음 없음 auth-username 없음 dg dg teimstamp 03/Feb/2020:14:15:00 -0400 03/Feb/2020:14:15:00 -0400 03/Feb/2020:14:15:00 -0400 request-line GET / HTTP/1.0 GET / HTTP/1.0 GET /foo HTTP/1.0 response-code 200 200 404 response-size 1024 477 0 3. 적중 계량하기 캐시는 수많은 HTTP요청을 처리하므로, 요청이 원 서버 까지 오지 않더라도 정상적으로 처리될 수 있어서, 클라이언트가 콘텐츠에 접근했다는 기록이 남지 않아 로그 파일에 누락이 발생하게 된다. 캐시를 파기 시킨다면, 문제 없이 로깅을 하지만, 요청에 대한 응답속도가 느려지고 원서버와 네트워크의 부하가 가중되는 문제를 야기한다. 적중 계량 규약은 HTTP의 확장으로, 캐시가 정기적으로 캐시 접근 통계를 원 서버에 보고하도록 한다. 완벽하진 않지만, 서버가 원하는 통계 정보를 받아볼 수 있는 방법을 제공한다.","link":"/2020/02/23/http-guide-chap21/"},{"title":"HTTP 완벽가이드 7장 part1","text":"7장 캐시 part1웹 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치다. 웹 요청이 캐시에 도착했을 때, 캐시된 로컬 사본이 존재한다면, 그 문서는 원 서버가 아니라 그 캐시로 부터 제공된다. 7.1 불필요한 데이터 전송 다수의 클라이언트가 하나의 페이지를 서버에 요청시에 서버는 같은 문서를 네트워크를 통해 각각 전송한다. 값비싼 네트워크 대역폭을 잡아먹고, 전송을 느리게 만들며, 웹 서버에 부하를 준다. 7.2 대역폭 병목 캐시는 네크워크 병목을 줄여준다. 많은 네트워크가 원격 서버보다 로컬 네트워크 클라이언트에 더 넓은 대역폭을 제공한다. 7.3 갑작스런 요청 쇄도(Flash Crowds) 많은 사람들이 거의 동시에 웹 문서에 접근할 때 트래픽이 급증하고 네트워크와 웹 서버의 장애를 일으키는데, 캐싱은 중요한 역할을 한다. 7.4 거리로 인한 지연 클라이언트와 서버 사이에 라우터가 그지 많지 않더라도, 빛의 속도 그 자체가 유의미한 지연을 유발한다. 클라이언트와 서버간의 거리가 멀수록, 커넥션의 개수가 많아지면, 네트워크 지연은 커지게 된다. 7.5 적중과 부적중캐시 적중(cache hit)이란 캐시에 요청이 도착했을 때, 만약 그에 대응하는 사본이 있다면 그것을 이용해 요청을 처리하는 것이다. 캐시 부적중(cache miss)이란 대응하는 사본이 없다면 그냥 원 서버로 전달된다. 7.5.1 재검사(Revalidation) 원 서버 리소스는 변경될 수 있기 때문에, 반드시 그들이 갖고 있는 사본이 최신인지 서버를 통해서 점검해야한다. 신선도 검사를 HTTP 재검사라고 부른다. 캐시는 스스로 원한다면 언제든지 사본을 재검사할 수 있다. 캐시가 문서를 수백만 개씩 갖고 있는 경우에는 네트워크 대역폭이 부족하므로, 캐시는 클라이언트가 사본을 요청하였으며 그 사본이 검사를 할 필요가 있을 정도로 충분히 오래된 경우에만 재검사를 한다. 7.5.2 적중률 캐시가 요청을 처리하는 비율을 캐시 적중률 이라고 부른다. 캐시 적중률이 100%에 근접할 수록 모든 요청이 캐시에 적중한 것이다. 일반적으로 40%면 웹 캐시로 괜찮다고 본다. 7.5.3 바이트 적중률 문서들이 모든 같은 크기가 아니기 때문에 문서 적중률이 모든 것을 말해주지 않는다. 바이트 단위 적중률은 캐시를 통해 제공된 모든 바이트의 비율을 표현한다. 문서 적중률을 개선하면 전체 대기시간(지연)이 줄어든다. 바이트 단위 적중률은 얼마나 많은 바이트가 인터넷으로 나가지 않았는지 보여준다. 바이트 단위 적중률을 개선하면 대역폭 절약을 최적화한다. 7.5.4 적중과 부적중의 구별 HTTP는 클라이언트에게 응답이 캐시 적중이었는지 아니었는지에 대해서 말해주지 않는다. 클라이언트는 Date 헤더 값을 현재 시각과 비교하여, 응답의 생성일이 더 오래되었다면 클라이언트는 응답이 캐시된 것임을 알아낼 수 있다. 7.6 캐시 토폴로지7.6.1 개인 전용 캐시 많은 에너지나 저장 공간을 필요로 하지 않으므로, 작고 저렴하다. 웹 브라우저는 개인 전용 캐시를 내장하고 있다. 대부분의 브라우저는 자주 쓰이는 문서를 개인용 컴퓨터의 디스크와 메모리에 캐시해 놓고, 사용자가 캐시 사이즈와 설정을 수정할 수 있도록 허용한다. 크롬에서는 특별한 url인 about:cache 를 통해 확인한다. 7.6.2 공용 프락시 캐시 로컬 캐시에서 문서를 제공하거나, 혹은 사용자의 입장에서 서버에 접근한다. 공용 캐시에는 여러 사용자가 접근하기 때문에, 불필요한 트래픽을 줄일 수가 있다. 캐시는 자주 찾는 객체를 단 한 번만 가져와 모든 요청에 대해 공유된 사본을 제공하여 네트워크 트래픽을 줄인다. 7.6.3 프락시 캐시 계층들 작은 캐시에서 캐시 부적중이 발생했을 때 더 큰 부모 캐시가 그 ‘걸러 남겨진’ 트래픽을 처리하도록 하는 계층 을 만드는 방식이 합리적인 경우가 있다. 클라이언트 주위에는 작고 저렴한 캐시를 사용하고, 계층 상단에는 많은 사용자들에 의해 공유되는 문서를 유지하기 위해 더 크고 강력한 캐시를 사용한다. 캐시 계층이 깊다면 캐시의 긴 연쇄를 따라가게 되고, 각 중간 프락시는 성능 저하가 발생한다. 7.6.4 캐시망, 콘텐츠 라우팅, 피어링 네트워크 아키텍쳐 중 캐시망을 만들고 복잡한 방법으로 서로 대화하여, 어떤 부모 캐시와 대화할 것인지, 아니면 요청이 캐시를 완전히 우회해서 원 서버로 바로 가도록 할것인지에 대한 커뮤니케이션 결정을 내린다.","link":"/2019/09/29/http-guide-chap7-1/"},{"title":"HTTP 완벽가이드 8장","text":"8장 통합점: 게이트웨이, 터널, 릴레이1. 게이트웨이 복잡한 리소스들을 한 개의 어플리케이션으로만 처리할 수 없다는 문제를 해결하기 위해서 만들었다. 리소스와 애플리케이션을 연결하는 역할을 한다. 요청을 받고 응답을 보내는 포털 같이 동작하는데, 동적인 콘텐츠를 생성하거나 데이터베이스에 질의를 보낼 수 있다. HTTP 트래픽을 다른 프로토콜로 자동으로 변환하여, HTTP 클라이언트가 다른 프로토콜을 알 필요 없이 서버에 접속할 수 있게 한다. 2. 프로토콜 게이트웨이 게이트웨에서 HTTP 트래픽을 바로 보낼 수 있다. 브라우저에 명시적으로 게이트웨이를 설정하여 자연스럽게 트래픽이 게이트웨이를 거쳐가게 하거나, 게이트웨이를 대리 서버(리버스 프락시)로 설정할 수 있다. 3. 리소스 게이트웨이 일반적으로 애플리케이션 서버는 목적지 서버와 게이트웨이를 한 개의 서버로 결합한다. 3.1 공용 게이트웨이 인터페이스 공용 게이트웨이 인터페이스(CGI)는 최초의 서버 확장이자 지금까지도 가장 널리 쓰이는 서버 확장이다. CGI 애플리케이션이 서버와 분리되면서 다양한 언어로 구현되며, 거의 모든 HTTP서버가 지원한다. CGI가 내부에서 어떤 처리를 하는지 사용자에게 보이지 않고, 내부적으로 일반적인 요청을 만든다. 3.2 서버 확장 API 서버 개발자는 웹 개발자가 자신의 모듈을 HTTP와 직접 연결할 수 있는 강력한 인터페이스인 서버 확장 API를 제공한다. 확장 API는 프로그래머가 자신의 코드를 서버에 연결하거나 서버의 컴포넌트를 자신이 만든 것으로 교체해버릴 수 있게 한다. 4. 애플리케이션 인터페이스와 웹 서비스 애플리케이션을 연결하면서 데이터를 교환하려는 두 애플리케이션 사이에서 프로토콜 인터페이스를 맞추는 일이 가장 까다로운 이슈이다. 웹 애플리케이션이 서로 통신하는데 사용할 표준과 프로토콜 집합을 개발하였다. 웹 서비스는 SOAP를 통해 XML을 사용하여 정보를 교환한다. 5. 터널 HTTP 프로토콜을 지원하지 않는 애플리케이션에 HTTP 애플리케이션을 사용해 접근하는 방법을 제공한다. HTTP 커넥션을 통해서 HTTP가 아닌 트래픽을 전송할 수 있고, 다른 프로토콜을 HTTP 위에 올릴 수 있다. 주로 HTTP 커넥션 안에 HTTP가 아닌 트래픽을 얹기 위해서 사용한다. 5.1 CONNECT로 HTTP 터널 커넥션 맺기 웹 터널은 HTTP의 CONNECT 메서드를 사용해 커넥션을 맺는다. CONNECT 메서드는 터널 게이트웨이가 임의의 목적 서버와 포트에 TCP 커넥션을 맺고 클라이언트와 서버 간에 오는 데이터를 무조건 전달하기를 요청한다. CONNECT 요청 시작줄을 제외하고는 다른 HTTP 메서드와 같다. 각 행은 CRLF로 끝나고, 헤더 목록의 끝은 빈 줄의 CRLF로 끝난다. CONNECT home.netscape.com:443 HTTP/1.0 User-agent: Mozilla/4.0 CONNECT 응답 클라이언트는 요청을 전송한 다음, 게이트웨이의 응답을 기다린다. 커넥션이 메시지를 전달하는 대신 바이트를 그대로 전달하기 때문에 콘텐츠의 형식을 기술하는 Content-Type 헤더를 포함할 필요가 없다. HTTP/1.0 200 Connection Established Proxy-agent: Netscape-Proxy/1.1 5.2 데이터 터널링, 시간, 커넥션 관리 터널을 통해 전달되는 데이터는 게이트웨이에서 볼 수 없어서, 게이트웨이는 패킷의 순서나 흐름에 대한 어떤 가정도 할 수 없다. 게이트웨이는 커넥션이 맺어지는 대로 헤더를 포함해서 읽어들인 모든 데이터를 서버에 전송해야 한다. 터널의 어느 부분이든 커넥션이 끊어지면, 그 곳으로부터 온 데이터는 반대편으로 전달되고, 그 다음 커넥션이 끊어졌던 터널의 끝단 반대편의 커넥션도 프락시에 의해서 끊어진다. 5.3 SSL 터널링 웹 터널은 방화벽을 통해서 암호화된 SSL 트래픽을 전달하려고 개발되었다. SSL 트래픽을 HTTP 커넥션으로 전송하여 80포트의 HTTP만을 허용하는 방화벽을 통과 시킨다. 5.4 SSL 터널링 vs HTTP/HTTPS 게이트웨이 HTTPS 프로토콜은 다른 프로토콜과 같은 방식으로 게이트웨이를 통과할 수 있다. 게이트웨이가 FTP를 처리하는 방식과 같다. 단점 클라이언트-게이트웨이 사이에는 보안이 적용되지 않은 일반 HTTP 커넥션이 맺어져 있다. 프락시가 인증을 담당하고 있기 때문에, 클라이언트는 원격 서버에 SS?L 클라이언트 인증을 할 수 없다. 게이트웨이는 SSL을 완벽히 지원해야 한다. 5.5 터널 보안에 대한 고려사항들 터널 게이트웨으는 통신하고 있는 프로토콜이 터널을 올바른 용도로 사용하고 있는지 검증할 방법이 없다. 터널의 오용을 최소화하기 위해서, 게이트웨이는 HTTPS 전용 포트인 443같이 잘 알려진 특정 포트만을 터널링할 수 있게 허용해야 한다. 6. 릴레이 HTTP 명세를 완전히 준수하지 않는 간단한 HTTP 프락시다. 커넥션을 맺기 위한 HTTP 통신을 한 다음, 바이트를 전달한다. 릴레이는 Connection 헤더를 제대로 처리하지 못해서 keep-alive 커넥션이 행(hang)에 걸리는 문제점이 생긴다. 웹 클라이언트는 Connection: Keep-Alive 헤더를 보내서, 릴레이에 커넥션을 맺기를 원한다는 내용의 요청 메시지를 전송한다. 릴레이가 HTTP 요청을 받지만, Connection 헤더를 이해하지 못하므로 요청을 서버로 넘긴다. 웹 서버가 프락시로부터 Connection: Keep-Alive헤더를 받으면, 릴레이가 keep-alive를 하기 바란다고 잘못된 결론을 내려버린다. 이 시점부터 웹 서버는 릴레이와 함께 keep-alive 통신을 하고, keep-alive의 규칙에 맞게 동작할 것이다. 릴레이는 웹 서버로부터 받은 Connection: Keep-Alive 헤더를 포함한 응답 메시지를 클라이언트에게 전달한다. 클라이언트와 서버는 keep-alive로 통신한다고 믿고 있지만, 실제로 통신하는 릴레이는 keep-alive가 무엇인지도 모른다. 원서버는 릴레이가 자신에게 커넥셔능ㄹ 계속 맺고 있기를 요청했다고 믿기 때문에 커넥션을 끊지 않을것이다. 따라서 릴레이는 커넥션이 끊길 때를 기다리며 계속 커넥션을 맺고(hang) 있을 것이다. 클라이언트가 응답 메시지를 받으면, 바로 다음 요청을 keep-alive 커넥션을 통해 릴레이에게 전송한다. 브라우저는 계속 돌고 있지만, 아무런 작업도 진행되지 않는다.","link":"/2019/10/13/http-guide-chap8/"},{"title":"코드스피츠85 2회","text":"왜 프론트엔드 개발자를 무시할까? 잘 모르기 때문에.. 프로그래밍 모델, 컴퓨터 내부, 컴퓨터 사이언스 내용에 대한 부족 바깥에 표현하는거에 관심 중급 이상이 넘어가면 얘기가 안통한다고 생각하게 됨 Parallelism 병렬성 병렬성이 동시성을 이해하는 것보다 쉽다. Worker가 동시에 투입되고 일을 동시에 처리할 수 있다. 프론트엔드에서는 네트워크에 무언가 요청을 하면 네트워크 서버가 돌고 클라이언트에서 돌고있다. Task에 할당되는 worker가 별도로 존재해서 자기만의 속도와 스케줄로 일을 처리한다. 각각의 Task가 하나의 메모리를 동시에 같이 사용하면 문제가 생긴다. 하나의 Task가 메모리를 사용하고 있으면 나머지 Task를 Blocking을 하는 방법을 사용 자바스크립트는 병행성이 막혀있다(es2018 이전까지) 함수형은 프로그래밍은 공유를 하지말고 특정 메모리만 쓰도록 한다 객체지향 프로그래밍은 공유하는 메모리를 인정할 수 밖에 없다 → 객체 식별을 새로 만들어진 값으로 하는게 아니라 포인터 참조로 되기 때문에 각각의 Task들이 하나의 메모리를 참조 할 수 있다 Concurrency 동시성 엄밀히 말하면 동시에 일어나지 않음 마치 동시에 일어나는 것처럼 보이는거임 메모리를 동시에 쓰는 경우가 없다 자바스크립트에서는 병행성이 없고 동시성만 있다 동시성과 병행성의 가장 큰 차이는 Worker가 몇명인지이다. 실제 세계의 Concurrency 한번에 하나만 하긴 하더라도 굉장히 복잡하게 많은 일을 한다 자바스크립트 Concurrencyengine work 브라우저는 렌더링을 포함한 수많은 엔진들이 하는 일들을 한다. (통신 준비, favicon 요청, console 초기화, 메모리 initialize 등등) → 멀티스레드로 수행한다. 자바스크립트 코드가 영향을받는 메모리 블럭을 수행할 때는 하나의 스레드를 사용한다. 자바스크립트 메모리에 영향을 주지않는다면 여러개의 스레드를 사용한다 queue에 걸리는게 없다면 engine work가 할일을 계속 수행한다 queue에 실행할 일이 생기면 run JS 실행한다 실행이 끝나면 다시 engine work 수행한다. check queue 자바스크립트 명령을 적재해 둔게 있는지 없는지 검사한다. callback queue를 바라본다. callback queue 브라우저 로딩에 들어가는 스크립트 callback queue 이벤트 리스너 callback queue 생산자 &amp; 소비자 ⇒ 멀티 스레드 패턴 소비자가 하나의 스레드 메모리에서 읽기만 한다. 소비자가 하나만 두는 것을 파이프 패턴이라 한다. network, timer, message, dom event는 멀티스레드로 돌리더라도 synchronize 문제가 생기지 않는다. callback queue를 중심으로 동시성과 병행성이 나뉜다. 병행성에서는 생산만, 동시성에서는 소비만 하는 패턴 setTimer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142const Item = class{ time; block; constructor(block, time) { this.block= block; this.time = time + performance.now();}const queue = new Set;const f = time=&gt; { queue.forEach(item=&gt;{ if(item.time &gt; time) return; queue.delete(item); item.block(); }); requestAnimationFrame(f);}requestAnimationFrame(f);const timeout = (block, time) =&gt; queue.add(new Item(block, time)); ``` - 함수는 어떻게 1초후에 일어나는걸까?- 밀리세컨마다 1초지났는지 계속 확인하다가 1초지났을때 실행한다- 푸쉬형을 선호한다 이벤트 기반의 프로그램을 짠다- 원하는 사건에 내 코드가 호출되었으면 좋겠다- 클릭할때 리스너가 뜨길 원한다(어떻게 동작하는지는 관여하고 싶ㅍ지 않다)- 브라우저는 개발자를 바보로 만든다...ㅠㅠ- 컴퓨터 사이언스로 보면 우리는 부탁만하는거다;- `performance.now()` 브라우저가 시작되고 몇초가 지났는지(나노초 가능)value 값- 불변- 메모리 자체가 아닌 그 자체로 판단배열은 여러개일수도 있고 똑같은 값을 넣을수도있다Set은 중복된 객체를 넣지 않기 위함객체 지향에서 객체에대한 collection은 배열이 아니라 Set이다## Non Blocking For const working = _ =&gt; {}; for(let i=0; i&lt; 100000; i++) working(); const nbFor = (max, load, block) =&gt; { let i = 0; const f = time =&gt; { let i = 0; const f = time =&gt; { let curr =load; while(curr-- &amp;&amp; i &lt; max) { block(); i++; } console.log(i); if(i&lt;max-1) requestAnimationFrame(i); }; requestAnimationFrame(i); } } nbFor(100, 10, working); -&gt; 10씩 끊어서 분산해서 처리한다 const nbFor = (max, load, block) =&gt; { let i = 0; const f = time =&gt; { let i = 0; const f = time =&gt; { let curr =load; while(curr-- &amp;&amp; i &lt; max) { block(); i++; } console.log(i); if(i&lt;max-1) timeout(f, 0); }; timeout(f, 0); } }## Generator자바스크립트에서 인터페이스는 특정키나 값이 들어있는 형태를 지칭한다 ⇒ 오브젝트의 형태루프의 주인공은 이터레이터다이터레이터에게 넥스트 함수를 호출하면 오브젝트를 리턴한다value, done이라는 키를 가진 오브젝트를 리턴 const infinity = (function*() { let i= 0; while(true) yield i++; })(); console.log(infinity.next());generator를 호출하면 iterator 객체가 나온다generator 자체로는 for..of를 사용 못함infinity 만들자마 즉시 호출이므로 iterator 객체이다function* 는 서스펜드 구간을 생성한다동기명령은 멈출수 없지만 generator는 멈출수 있다메모리 적재시에 명령마다 레코드라는것으로 감싸서 적재해두었고 하나를 실행할때마다 레코드를 풀어서 실행 → 서스펜드yield 호출시에 서스펜드(멈춤)resume(다시 시작)명령어를 중간에 끊을수 있기 때문에 무한 크기의 배열을 만들수 있다 const gene = function*(max, load, block) =&gt; { let i = 0, curr = load; while(i&lt;max){ if(curr--){ block(); i++; }else{ curr=load; console.log(i); yield; } } const nbFor = (max, load, block)=&gt;{ const iterator = gene(max, load, block); const f=_=&gt;iterator.next().done||timeout(f); timeout(f,0); };지역변수를 사용한다제어구조를 외부에서 통제하도록 되어있다## Promise const gene2 = function*(max, load, block) =&gt; { let i = 0; while(i &lt; max){ yield new Promise(res =&gt; { let curr = load; while(curr– &amp;&amp; i&lt;max){ block(); i++; } console.log(i); timeout(res, 0); }); }};const nbFor = (max, load, block)=&gt;{ const iterator = gene(max, load, block); const next = ({value, done})=&gt; done || value.then(v=&gt;next(iiterator.next())); next(iterator.next());};```callback 스타일은 제어권을 잃는다 우리가 원하는 시간에 callback이 오면 좋겠다 서버 응답은 우리가 원하는데로 오지 않는다 제어권을 통제하기 위해서는 프로미스 객체를 가지고 있다가 내가 원할때 then을 호출 →반제어권 promise와 callback의 차이 → 내가 원할때 then을 호출할 수 있다 promise.then으로 쓰면 callback과 똑같다 generator와 promise를 섞어서 사용하면 외부제어에 일부를 개입할 수 있는 제어 역전을 결정할 수 잇따","link":"/2019/11/10/codespitz85-2/"},{"title":"HTTP 완벽가이드 11장","text":"11장 클라이언트 식별과 쿠키목표 서버가 통신하는 대상을 식별하는 데 사용하는 기술을 알아본다 1. 개별접촉웹 서버는 요청을 보낸 사용자를 식별하거나 방문자가 보낸 연속적인 요청을 추적하기 위해 약간의 정보를 이용한다. 현대의 웹사이트 들은 개인화된 서비스를 제공하기 위해 여러가지 방식을 사용한다. 개별 인사 사용자에게 특화된 환영 메시지나 페이지 내용을 만든다 사용자 추천 고객의 흥미가 무엇인지 파악하고 고객에게 맞춤으로 제품을 추천한다 저장된 사용자 정보 온라인 쇼핑 고객은 주소와 신용카드 정보를 매번 입력하는 것을 싫어한다 온라인 쇼핑이 고객을 식별하고 나면 쇼핑을 더 편리하게 하도록 사용자 정보를 사용한다 세션 추적 HTTP 트랜잭션은 상태가 없어서 각 요청 및 응답은 독립적으로 일어난다 많은 웹사이트에서 사용자가 사이트와 상호작용 할 수 있게 남긴 사용자 정보를 유지하기 위한 HTTP 트랜잭션을 식별할 방법이 필요하다 2. HTTP 헤더가장 일반적인 HTTP 요청 헤더 기술 From: 사용자의 이메일 주소 User-Agent: 사용자의 브라우저 Referer: 사용자가 현재 링크를 타고 온 근원 페이지 Authorization: 사용자 이름과 비밀번호 Client-ip: 클라이언트의 IP주소 X-Forwarded-For: 클라이언트의 IP주소 Cookie: 서버가 생성한 ID 라벨 3. 클라이언트 IP 주소초기에는 사용자 식별에 클라이언트의 IP 주소를 사용하려고 하였다 확실한 IP 주소를 가지고 있고, 그 주소가 절대 바뀌지 않고, 웹 서버가 요청마다 클라이언트의 IP를 알 수 있다면, 문제가 되지 않는다 클라이언트 IP로 사용자를 식별한다면 많은 단점을 가지게 된다 만약 여러 사용자가 같은 컴퓨터를 사용한다면 그들을 식별할 수 없다 인터넷 서비스 제공자(ISP)는 사용자가 로그인하면 동적으로 IP 주소를 할당하기 때문에, 사용자는 매번 다른 주소를 받아, 웹 서버는 사용자를 IP 주소로 식별 할 수 없다 사용자들은 인터넷 사용시에 네트워크 주소 변환(Network Address Translation) 방화벽을 사용하는데, 방화벽은 사용자의 실제 IP를 숨기고 방화벽 IP 주소로 변환하므로 식별이 어렵다 HTTP 프락시와 게이트웨이는 원 서버에 새로운 TCP 연결을 한다. 웹 서버는 클라이언트의 IP 주소 대신 프락시 서버의 IP 주소를 본다 4. 사용자 로그인웹 서버는 사용자 이름과 비밀번호로 인증할 것을 요구해서 명시적으로 식별 요청할 수 있다 HTTP는 WWW-Authenticate와 Authorization 헤더를 사용해 웹 사이트에 사용자 이름을 전달하는 자체적인 체계를 가지고 있다. 1) 서버에서, 사용자가 사이트에 접근하기 전에 로그인을 시키고자 한다면 HTTP 401 ?Login Required 응답 코드를 브라우저에 보낼 수 있다. 2) 브라우저는 로그인 화면을 보여주고, 다음 요청부터 Authorization 헤더에 정보를 기술하여 보낸다. 5. 뚱뚱한 URL웹 사이트는 사용자의 URL마다 버전을 기술하여 사용자를 식별하고 추적하기도 한다. 웹 서버는 URL에 있는 상태 정보를 유지하는 하이퍼링크를 동적으로 생성한다. 뚱뚱한 URL은 사이트를 브라우징 하는 사용자를 식별하는데 사용할 수 있지만, 여러 문제들을 가지고 있다. 브라우저 보이는 URL이 새로운 사용자들에게는 혼란을 준다. URl은 특정 사용자와 세션에 대한 상태 정보를 포함하므로, 해당 주소를 공유하게 된다면 개인정보를 공유하게 되는 것이다. URL로 만드는 것은 URL이 달라지기 때문에 기존 캐시에 접근할 수 없다는 것을 의미한다. 뚱뚱한 URL에 해당하는 HTML 페이지를 다시 그려야한다. 사용자가 특정 뚱뚱한 URL을 북마킹하지 않는 이상, 로그아웃하면 모든 정보를 잃는다. 6. 쿠키사용자를 식별하고 세션을 유지하는 방식중에서 가장 널리 사용되는 방식이다. 쿠키는 매우 중요한 웹 기술이며, 새로운 HTTP 헤더를 정의한다. 6.1 쿠키의 타입 세션 쿠키(session cookie)와 지속 쿠키(persistent cookie) 타입으로 나뉜다. 세션 쿠키는 사용자가 브라우저를 닫으면 삭제된다. 지속 쿠키는 디스크에 저장되어, 브라우저를 닫거나 컴퓨터를 재시작하더라도 남아있다. 6.2 쿠키는 어떻게 동작하는가쿠키는 서버가 사용자에게 “안녕, 내 이름은…”라고 적어서 붙이는 스티커와 같다. 웹 서버는 사용자를 식별하기 위해 임의의 이름=값 형태로 쿠키에 할당한다. 할당된 리스트는 Set-Cookie 또는 Set-Cookie2 같은 HTTP 응답 헤더에 기술되어 사용자에게 전달한다. 6.3 쿠키 상자: 클라이언트 측 상태쿠키는 브라우저가 서버 관련 정보를 저장하고, 사용자가 해당 서버에 접근할 때마다 그 정보를 함께 전송하는 것이다. 브라우저는 쿠키 정보를 저장할 책임이 있는데, 이 시스템을 클라이언트 측 상태라고 한다. 6.4 사이트마다 각기 다른 쿠키들브라우저는 쿠키 전부를 모든 사이에 보내지 않고, 보통 두세 개의 쿠키만을 보낸다. 이유는 다음과 같다. 쿠키를 모두 전달하면 성능이 크게 저하된다. 대부분 서버에 특화된 이름/값 쌍을 이루므로, 대부분 사이트에서는 인식하지 않는 무의미한 값이다. 특정 사이트에서 제공한 정보를 신뢰하지 않는 사이트에 가지고 갈 수 있으므로 잠재적인 개인정보 문제를 일으킬 수 있다. 6.5 쿠키 구성요소현재 사용되는 쿠키로 Version 0(넷스케이프 쿠키)과 Version 1(RFC 2965) 쿠키가 존재한다. Version 0(넷스케이프 쿠키) 최초의 쿠키 명세 Set-Cookie: name=value [;expires=date] [;path=path] [;domain=domain] [;secure] Cookie: name1=value1 [;name2=value2]… Version 1 (RFC 2965) 쿠키 쿠키의 확장 버전으로 Version 0 시스템과도 호환된다. 넷스케이프 버전보다 복잡하며, 아직 모든 브라우저나 서버가 완전히 지원하지 않는다. 주요 변경사항 쿠키마다 그 목적을 설명하는 설명문이 있다. 쿠키의 생명주기를 결정할 수 있다(Max-Age) URL의 포트번호로도 쿠키를 제어할 수 있다. 브라우저가 닫히면 쿠키를 강제로 삭제할 수 있다. 6.6 쿠키와 세션 추적쿠키는 웹 사이트에 수차례 트랜잭션을 만들어내는 사용자를 추적하는 데 사용한다. Amazon.com 사이트에 방문하면 일어나는 트랜잭션의 연속을 알아본다. a) 브라우저가 Amazon.com 페이지를 처음 요청한다. b) 서버는 클라이언트를 전자상거래 소프트웨어 URL로 리다이렉트 시킨다. c) 클라이언트는 리다이렉트 URL로 요청 보낸다. d) 서버는 응답에 두 개의 세션 쿠키를 기술하고 사용자를 다른 URL로 리다이렉트 시키며, 클라이언트는 다시 이 쿠키들을 첨부하여 요청을 보낸다. e) 클라이언트는 새로운 URL을 요청을 팡서 받은 두 개의 쿠키와 함께 보낸다. f) 서버는 home.html 페이지로 리다이렉트 시키고 쿠키 두 개를 더 첨부한다. g) 클라이언트는 home.html 페이지를 가져오고 총 네 개의 쿠키를 전달한다. h) 서버는 콘텐츠를 보낸다. 6.7 쿠키와 캐싱쿠키 트랜잭션과 관련된 문서를 캐싱하는 것은 주의해야 한다. 이전 사용자의 쿠키가 다른 사용자에게 할당되어 누군가의 개인정보가 유출될 수 있다. 캐시를 다루는 기본 원칙 캐시되지 말아야 할 문서가 있다면 표시하라 문서가 Set-Cookie 헤더를 제외하고 캐시를 해도 될 경우라면 Cache-Control: no-cache=&quot;Set-Cookie&quot; 를 명시적으로 기술한다. Set-Cookie 헤더를 캐시하는 것에 유의하라 같은 Set-Cookie 헤더를 여러 사용자에게 보내게 되면, 사용자 추적을 실패하게 된다. 원 서버는 Cache-Control: must-revalidate, max-age=0 헤더를 캐시된 문서에 추가함으로써 재검사가 일어나게 할 수 있다. Cooke 헤더를 가지고 있는 요청을 주의하라 요청이 Cookie 헤더와 함께 오면, 결과 콘텐츠가 개인정보를 담고 있을 수도 있다는 힌트이다. Set-Cookie가 있는 이미지에 대해서는 캐시를 하지만 Set-Cookie가 있는 텍스트는 캐시를 하지 않는 캐시도 있다. 캐시 이미지에 파기 시간이 0인 Cookie 헤더를 설정해서 매번 재검사를 하도록 강제한다.","link":"/2019/11/10/http-guide-chap11/"},{"title":"HTTP 완벽가이드 3장","text":"3장 HTTP 메시지3.1 메시지의 흐름3.1.1. 메시지는 원 서버 방향을 인바운드로 하여 송신된다. 메시지가 원 서버로 향하는 것을 인바운드로 이동하는 것이다. 모든처리가 끝난 뒤에 사용자 에이전트로 돌아오는 것은 아웃바운드로 이동하는 것이다. 3.1.2 다운스트림으로 흐르는 메시지 HTTP 메시지는 강물과 같이 흐른다. 요청이나 응답 상관없이 메시지는 다운스트림으로 흐른다. 3.2 메시지의 각 부분HTTP 메시지는 시작줄, 헤더, 본문으로 구성된 구조화된 블록이다. 시작줄은 어떤 메시인지 서술하고, 헤더는 속성, 본문은 데이터를 담고 있으며, 본문은 존재하지 않을 수 있다. 3.2.1 메시지 문법요청메시지 형식 &lt;메서드&gt; &lt;요청URL&gt; &lt;버전&gt; &lt;헤더&gt; &lt;엔터티 본문&gt;응답메시지 형식 &lt;버전&gt; &lt;상태 코드&gt; &lt;사유 구절&gt; &lt;헤더&gt; &lt;엔터티 본문&gt;메서드 클라이언트가 서버에 리소스 요청 시에 서버가 수행하길 원하는 동작이다. 요청URL 리소스를 지칭하는 완전한 URL 혹은 URL의 경로 구성요소다. 완전하지 않은 URL이라고 하더라도, 클라이언트와 서버와 직접 대화를 하면서 리소스를 가리키는 절대 경로이기만 하면, 문제가 없다. 버전 사용중인 HTTP의 버전이다. HTTP/&lt;메이저&gt;.&lt;마이너&gt; 로 구성된다. 상태 코드 요청 중에 무엇이 일어났는지 설명하는 세 자리의 숫자다. 각 코드의 첫 번째 자릿수는 상태의 일반적인 분류를 나타낸다. 사유 구절(reason-phrase) 숫자로 구성된 상태 코드를 사람이 이해 가능하도록 나타내는 짧은 문구이다. 헤더들 이름 : 공백 or 값 형태의 순서대로 0개 이상 나타난다. 엔터티 본문 임의의 데이터 블록을 포함하지만, 모든 메시지가 엔터티 본문을 갖지 않는다. 널리 쓰이는 규칙이나 지키지 않는 구현체와의 호환을 위해, 클라이언트와 서버는 마지막 CRLF(빈줄) 없이 끝나는 메시지도 받아들일 수 있도록 해야 한다. 3.2.2. 시작줄요청줄 서버에게 리소스에 대해 무언가를 해달라고 요청한다. 요청 URL, 어떤 동작을 해야하는지에 대한 메서드, HTTP버전을 포함한다. 응답줄 수행 결과에 대한 상태 정보와 결과 데이터를 클라이언트에게 돌려준다. HTTP버전, 숫자로 된 상태 코드, 수행 상태에 대해 설명해주는 사유구절을 포함한다. 메서드 요청의 시작줄은 메서드로 시작하며, 서버가 무엇을 해야하는지 말해준다. 메서드 설명 본문이 있는가? GET 서버에서 어떤 문서를 가져온다. 없음 HEAD 서버에서 어떤 문서에 대해 헤더만 가져온다. 없음 POST 서버가 처리해야 할 데이터를 보낸다. 있음 PUT 서버에 요청 메시지의 본문을 저장한다. 있음 TRACE 메시지가 프락시를 거쳐 서버에 도달하는 과정을 추적한다. 없음 OPTIONS 서버가 어떤 메서드를 수행할 수 있는지 확인한다. 없음 DELETE 서버에서 문서를 제거한다. 없음 상태코드 응답의 시작줄에 위치하며, 클라이언트에게 무엇이 일어났는지 말해준다. 현재 버전의 HTTP는 적은 수의 코드만 정의되어 있다. 전체 범위 정의된 범위 분류 100-199 100-101 정보 200-299 200-206 성공 300-399 300-305 리다이렉션 400-499 400-405 클라이언트 에러 500-599 500-505 서버 에러 사유 구절 응답 시작줄의 마지막 구성요소로, 상태 코드에 대한 글로 된 설명을 제공한다. HTTP 명세는 사유 구절이 어떻게 구성되어야 하는지에 대한 엄격한 규칙이 존재하지 않는다. 버전 번호 HTTP/x.y 형식으로 요청과 응답 메시지에 모두 존재한다. HTTP로 대화하는 애플리케이션들에게 대화 상대의 능력과 메시지의 형식에 대한 단서를 제공해주기 위한것이다. 3.2.3 헤더 HTTP 헤더는 여러 헤더 필드를 정의한다. 애플리케이션은 자유롭게 자신만의 헤더를 만들 수 있다. HTTP/1.0 200 OK Content-Type: image/gif Content-Length: 8572 Server: Test Server Version 1.0 3.2.4 엔터티 본문 HTTP 메시지의 구성 요소 중 선택적으로 HTTP가 수송하도록 설계된 화물이라고 할 수 있다. 이미지, 비디오, HTML문서, 소프트웨어 애플리케이션, 전자우편 등 여러 종류의 디지털 데이터를 실어 나른다. 3.3 메서드 모든 서버가 모든 메서드를 구현하지는 않는다. 3.3.1 안전한 메서드 GET, HEAD 는 안전한 메서드로 HTTP 요청 후에 서버에서 어떠한 자원의 변경이 일어나지 않는다. 3.3.2 GET 가장 흔히 사용되는 메서드로 서버에게 리소스를 달라고 요청시에 사용된다. 3.3.3 HEAD GET처럼 행동하지만, 서버는 응답으로 헤더만을 돌려준다. 리소스를 가져오지 않고도 그에 대해 무엇인가를 알아 낼 수 있다. 응답의 상태 코드를 통해, 개체가 존재하는지 확인 할 수 있다. 헤더를 확인하여 리소스가 변경되었는지 검사할 수 있다. 3.3.4 PUT 서버가 요청의 본문을 가지고 요청 URL의 이름대로 새 문서를 만들거나, 이미 URL이 존재한다면 본문을 사용해서 교체하는 것이다. 3.3.5 POST 서버에 입력 데이터를 전송하기 위해 설계되었다. HTML 폼을 지원하며, 담긴 데이터는 서버로 전송된다. 3.3.6 TRACE 클라이언트에게 자신의 요청이 서버에 도달했을 때 어떻게 보이게 되는지 알려준다. 클라이언트는 자신과 목적지 서버 사이에 있는 모든 HTTP 애플리케이션의 요청/응답 연쇄를 따라가면서 자신이 보낸 메시지가 망가졌거나 수정되었는지, 만약 그렇다면 어떻게 변경되었는지 확인할 수 있다. 3.3.7 OPTIONS 웹 서버에게 여러 가지 종류의 지원 범위에 대해 물어본다. 리소스에 대해 실제로 접근하지 않고도 어떻게 접근하는 것이 최선인지 확인할 수 있는 수단을 클라이언트 애플리케이션에게 제공한다. 3.3.8 DELETE 서버에게 요청 URL로 지정한 리소스를 삭제할 것을 요청한다. 3.4 상태 코드3.4.1 100-199: 정보성 상태 코드 HTTP/1.1에서 도입되었다. 3.4.2 200-299: 성공 상태 코드 클라이언트가 요청을 보내고, 요청이 성공한다. 서버는 성공을 의미하는 상태 코드의 배열을 갖고 있으며, 각각의 요청에 대응한다. 3.4.3 300-399: 리다이렉션 상태 코드 클라이언트가 관심있어 하는 리소스에 대해 다른 위치를 사용하라고 말해주거나 그 리소스의 내용 대신 다른 대안 응답을 제공한다. 3.4.4 400-499: 클라이언트 에러 상태 코드 클라이언트가 서버에게 알 수 없는 요청을 보냈을때 나타난다. 3.4.5 500-599: 서버 에러 상태 코드 클라이언트가 올바른 요청을 보냈음에도 서버 자체에서 에러가 발생하는 경우다. 3.5 헤더3.5.1 일반 헤더 클라이언트와 서버 양쪽 모두가 사용하고 메시지에 대한 아주 기본적인 정보를 제공한다. ex)Date: Tue, 3 Oct 1974 02:16:00 GMT 일반 캐시 헤더 HTTP 애플리케이션에게 매번 원 서버로부터 객체를 가져오는 대신, 로컬 복사본으로 캐시할 수 있도록 해준다. 3.5.2 요청 헤더 요청 메시지에서만 의미를 갖는다. 요청이 최초 발생한 곳에서 누가 혹은 무엇이 그 요철을 보냈는지에 대한 정보나 클라이언트의 선호나 능력에 대한 정보를 제공한다. ex)Accept: */* 3.5.3 응답 헤더 응답 메시지는 그들만의 응답 헤더를 갖는다. 누가 응답을 보내고 있는지, 응답자의 능력은 어떻게 되는지 알려주면, 응답에 대한 특별한 설명도 제공할 수 있다. ex)Server: Tiki-Hut/1.0 3.5.4 엔터티 헤더 요청과 응답 양 타입의 메시지에 모두 나타날 수 있다. 개체의 타입부터 주어진 리소스에 대해 요청할 수 있는 유효한 메서드들까지, 광범위한 정보를 제공한다. ex)Content-Type: texthtml; charset=iso-latin-1 3.5.5 확장 헤더 애플리케이션 개발자들에 의해 만들어졌지만 HTTP 명세에는 추가되지 않은 비표준 헤더다.","link":"/2019/08/18/http-guide-chap3/"},{"title":"HTTP 완벽가이드 4장","text":"4장 커넥션 관리4.1 TCP 커넥션 모든 HTTP통신은 네트워크 프로토콜의 집합인 TCP/IP를 통해 이루어진다. 커넥션이 맺어지면, 메시지가 손실, 손상되거나 순서가 바뀌지 않고 안전하게 전달된다. 커넥션 과정 1) 브라우저가 https://bebiangel.github.io 라는 호스트 명을 추출한다. 2) 브라우저가 호스트 명에 대한 IP 주소를 찾는다. 3) 브라우저가 포트 번호(80)를 얻는다. 4) 브라우저가 IP 주소의 80포트로 TCP 커넥션을 생성한다. 5) 브라우저가 서버로 HTTP GET 요청 메시지를 보낸다. 6) 브라우저가 서버에서 온 HTTP 응답 메시지를 읽는다. 7) 브라우저가 커넥션을 끊는다. 4.1.1 신뢰할 수 있는 데이터 전송 통로인 TCPTCP는 HTTP에게 신뢰할만한 통신 방식을 제공한다. 4.1.2 TCP 스트림은 세그먼트로 나뉘어 IP 패킷을 통해 전송된다TCP는 IP 패킷 이라는 작은 조각을 통해 데이터를 전송한다. 4.1.3 TCP 커넥션 유지하기TCP커넥션은 여러 개를 가지고 있고, 포트 번호를 통해서 여러개의 커넥션을 유지한다. &lt;발신지 IP 주소, 발신지 포트, 수신지 IP주소, 수신지 포트&gt; 네 가지 항목으로 커넥션을 생성하고, 서로 다른 TCP 커넥션은 일부는 같을 수 있으나 모든 항목이 같을 수는 없다. 4.2 TCP의 성능에 대한 고려 HTTP는 TCP 바로 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 TCP 성능에 영향을 받는다. HTTP의 커넥션 최적화 요소들을 통해서 더 좋은 성능의 HTTP 애플리케이션을 설계하고 구현한다. 4.2.1 HTTP 트랜잭션 지연 트랜잭션을 처리하는 시간은 TCP 커넥션을 설정하고, 요청을 전송하고, 응답 메시지를 보내는것에 비하면 상당히 짧다 트랜잭션을 지연시키는 원인 1) 클라이언트가 URI에 기술된 호스트에 방문한적이 없다면, DNS 이름 분석을 사용하여 호스트명을 IP 주소로 변환하는데 수십 초의 시간이 걸린다. 2) 클라이언트는 TCP 커넥션 요청을 서버에게 보내고 서버가 커넥션 허용 응답을 회신하기를 기다린다. 서버에서 수백개의 HTTP 트랜잭션이 만들어진다면 많은 소요시간이 걸린다. 3) 커넥션이 맺어지고 클라이언트는 HTTP 요청을 전송한다. 서버에서는 요청 메시지를 읽고 처리하는데 시간이 소요된다. 4) 서버에서 HTTP 응답을 보내는데 시간이 걸린다. 4.2.2 성능 관련 중요 요소고성능의 HTTP 소프트웨어를 개발하기 위해서 알아야 할 요소들 TCP 커넥션의 핸드셰이크 설정 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start) 데이터를 한데 모아 한 번에 전송하기 위한 네이글(nagle) 알고리즘 TCP의 편승 확인응답을 위한 확인응답 지연 알고리즘 TIME_WAIT 지연과 포트 고갈 4.2.3 TCP 커넥션 핸드셰이크 지연 TCP 커넥션을 열때, 커넥션을 맺기 위한 조건을 맞추기 위해 연속적으로 IP 패킷을 교환한다. 작은 크기의 데이터 전송시에 커넥션을 사용한다면, HTTP 성능을 저하시킬 수 있다. 핸드셰이크 순서 1) 커넥션 생성시에 작은 TCP 패킷을 서버에게 보내는데, 커넥션 생성 요청이라는 의미를 가진SYN 플래그를 가진다. 2) 서버가 커넥션을 받으면 커넥션 매개변수를 산출하고, 커넥션 요청이 받아들여졌음을 의미하는 SYN 과 ACK 플래그를 포함한 TCP 패킷을 클라이언트에게 보낸다. 3) 클라이언트는 커넥션이 잘 맺어졌음을 서버에게 다시 확인응답 신호를 보낸다. 클라이언트는 확인응답 패킷과 데이터를 함께 보낼수 있다. 4.3 HTTP 커넥션 관리4.3.1 흔히 잘못 이해하는 Connection 헤더 HTTP Connection 헤더 필드는 토큰을 쉼표로 구분하여 가지고 있으며, 다른 커넥션에 전달되지 않는다. Connection 헤더에 있는 모든 헤더 필드는 메시지를 다른 곳으로 전달하는 시점에 삭제되어야한다. 4.3.2 순차적인 트랜잭션 처리에 의한 지연 여러개의 리소스를 받아와야 하는 화면이 있다면, 각각의 리소스의 HTTP 트랜잭션을 만들어야한다. 특정 브라우저의 경우 객체를 화면에 배치하려면 객체의 크기를 알아야 하기 때문에, 모든 객체를 내려받기 전까지는 빈 화면을 보여준다. HTTP 커넥션의 성능을 향상시키는 기술 병렬(parallel) 커넥션 여러 개의 TCP 커넥션을 통한 동시 HTTP 요청 지속(persistent) 커넥션 커넥션을 맺고 끊는 데서 발생하는 지연을 제거하기 위한 TCP 커넥션의 재활용 파이프라인(piplined) 커넥션 공유 TCP 커넥션을 통한 병렬 HTTP 요청 다중(multiplexed) 커넥션 요청과 응답들에 대한 중재 4.4. 병렬 커넥션 브라우저가 HTML 페이지를 보여주는데 필요한 리소스를 순서대로 받는다면 너무 느리다. HTTP는 클라이언트가 여러 개의 커넥션을 맺음으로써 여러 개의 HTTP 트랜잭션을 병렬로 처리할 수 있게 한다. 4.4.1 병렬 커넥션은 페이지를 더 빠르게 내려받는다 커넥션의 대역폭 제한과 커넥션이 동작하지 않고 있는 시간을 활용하면, 객체가 여러개 있는 웹페이지를 더 빠르게 내려받을수 있을 것이다. 각 커넥션의 지연 시간을 겹치게 하면 총 지연 시간을 줄일 수 있다. 인터넷 대역폭을 한 개의 커넥션이 다 써버리지 않고, 나머지 객체를 내려받는 데에 남은 대역폭을 사용한다. 4.4.2 병렬 커넥션이 항상 더 빠르지는 않다 클라이언트의 네트워크 대역폭이 좁을 때는 대부분 시간을 데이터 전송하는 데만 쓸 것이다. 제한된 대역폭 내에서 각 객체를 전송받는 것은 느리기 때문에 성능상의 장점이 사라진다. 서버는 다른 여러 사용자의 요청도 함께 처리해야 하기 때문에 수백 개의 커넥션을 허용하는 경우는 드물다. 4.5 지속 커넥션 클라이언트가 같은 사이트에 여러 개의 커넥션을 맺는 속성을 지역성(site locality)라 한다. HTTP/1.1을 지원하는 기기는 처리가 완료된 후에도 TCP 커넥션을 유지하여 앞으로 있을 HTTP 요청에 재사용이 가능하다. 처리가 완료된 후에도 계속 연결된 상태로 있는 TCP 커넥션을 지속 커넥션이라고 부른다. 4.5.1 지속 커넥션 vs 병렬 커넥션병렬 커넥션 단점 각 트랜잭션마다 새로운 커넥션을 맺고 끊기 때문에 시간과 대역폭이 소요된다. 각각의 새로운 커넥션은 TCP 느린 시작 때문에 성능이 떨어진다. 실제로 연결할 수 잇는 병렬 커넥션의 수에는 제한이 있다. 지속 커넥션 장점 커넥션을 맺기 위한 사전 작업과 지연을 줄여주고, 커넥션의 수를 줄여준다. 지속 커넥션 단점 지속 커넥션을 잘못 관리할 경우, 계속 연결된 상태로 잇는 수많은 커넥션이 쌓인다. 로컬의 리소스 그리고 원격의 클라이언트와 서버의 리소스에 불필요한 소모를 발생한다. 지속 커넥션은 병렬 커넥션과 함께 사용될 때에 가장 효과적이다. 4.5.2 HTTP/1.0+의 Keep-Alive 커넥션 커넥션을 맺고 끊는 데 필요한 작업이 없어서 시간이 단축된다. keep-alive가 HTTP/1.1 명세에서는 빠졌지만, 아직 널리 사용되고 있어서 HTTP 애플리케이션은 그것을 처리할 수 있게 개발해야 한다. keep-alive 헤더 사용은 선택 사항이지만, Connection:Keep-Alive 헤더가 있을 때만 사용 할 수 있다. 4.6 파이프라인 커넥션 지속 커넥션을 통한 파이프라이닝은 keep-alive 커넥션의 성능을 높여준다. 파이프라인의 제약조건 HTTP 클라이언트는 커넥션이 지속 커넥션인지 확인하기 전까지는 파이프라인을 이어서는 안된다. HTTP 응답은 요청 순서와 같게 와야한다. HTTP 클라이언트는 커넥션이 언제 끊어지더라도, 완료되지 않은 요청이 파이프라인에 있으면 언제든 다시 요청을 보낼 준비가 되어 있어야 한다. HTTP 클라이언트는 POST 요청같이 반복해서 보낼 경우 문제가 생기는 요청은 파이프라인으로 보내면 안된다. 4.7 커넥션 끊기에 대한 미스터리 커넥션 관리(언제 어떻게 끊기는지)는 명확한 기준이 없다. HTTP 클라이언트, 서버 혹은 프락시든 언제든지 TCP 전송 커넥션을 끊을 수 있다. 커넥션이 에러가 없더라도 언제든 끊을 수 있다.","link":"/2019/08/25/http-guide-chap4/"},{"title":"HTTP 완벽가이드 5장","text":"5장 웹서버5. 1 웹 서버가 하는 일 커넥션을 맺는다. 클라이언트의 접속을 받아들이거나, 원치 않는 클라이언트라면 닫는다. 요청을 받는다. HTTP 요청 메시지를 네트워크로부터 읽어드린다. 요청을 처리한다. 요청 메시지를 해석하고 행동을 취한다. 리소스에 접근한다. 메시지에서 지정한 리소스에 접근한다. 응답을 만든다. 올바른 헤더를 포함한 HTTP 응답 메시지를 생성한다. 응답을 보낸다. 응답을 클라이언트에게 돌려준다. 트랜잭션을 로그로 남긴다. 로그 파일에 트랜잭션 완료에 대한 기록을 남긴다. 5.2 단계 1: 클라이언트 커넥션 수락클라이언트가 이미 서버에 대해 열려있는 지속적 커넥션을 갖고 있다면, 클라이언트는 요청을 보내기 위해 그 커넥션을 사용할 수 있다. 5.2.1 새 커넥션 다루기 클라이언트가 웹서버에 TCP 커넥션 요청을 하면, 웹 서버는 커넥션을 맺고 IP 주소를 추출하여 어떤 클라이언트가 있는지 확인한다. 서버는 새 커넥션을 커넥션 목록에 추가하고 커넥션에서 오가는 데이터를 지켜보기 위한 준비를 한다. 웹 서버는 어떤 커넥션이든 마음대로 거절하거나 즉시 닫을 수 있다. 5.2.2 클라이언트 호스트 명 식별 웹 서버는 역방향 DNS를 사용해서 클라이언트의 IP 주소를 호스트명으로 변환하도록 설정되어 있다. 호스트 명 룩업은 꽤 시간이 많이 걸릴 수 있어 웹 트랜잭션을 느려지게 할 수 있다. 5.2.3 ident를 통해 클라이언트 사용자 알아내기 ident 프로토콜은 서버에게 어떤 사용자 이름이 HTTP 커넥션을 초기화 했는지 찾아낼 수 있게 한다. 웹 서버 로깅에서 유용하여, 일반 로그 포맷의 두 번째 필드는 각 HTTP 요청의 사용자 이름을 담는다. 5.3 단계 2: 요청 메시지 수신커넥션에 데이터가 도착하면, 웹 서버는 네트워크 커넥션에서 그 데이터를 읽어 들이고 파싱하여 요청 메시지를 구성한다. 요청줄을 파싱하여 요청 메서드, 지정된 리소스의 식별자, 버전 번호를 찾는다. 메시지 헤더들을 읽는다. 각 메시지 헤더는 CRLF로 끝난다. 헤더의 끝을 의미하는 CRLF로 끝나는 빈 줄을 찾아낸다. 요청 본문이 있다면, 읽어 들인다. 5.3.1 메시지의 내부 표현웹 서버는 요청 메시지를 쉽게 다룰 수 있도록 내부의 자료 구조에 저장한다. 5.3.2 커넥션 입력/출력 처리 아키텍쳐 웹 서버는 수천 개의 커넥션을 동시에 열 수 있도록 지원한다. 커넥션들은 웹 서버가 전 세계의 클라이언트들과 각각 한 개 이상의 커넥션을 통해 통신할 수 있게 해준다. 웹 서버 아키텍쳐의 차이에 따라 요청을 처리하는 방식도 달라진다. 단일 스레드 웹 서버 한 번에 하나씩 요청을 처리한다. 트랜잭션이 완료되면, 다음 커넥션이 처리된다. 처리 도중에 모든 다른 커넥션은 무시된다. 멀티프로세스와 멀티스레드 웹 서버 웹 서버는 요청을 동시에 처리하기 위해 여러 개의 프로세스 혹은 고효율 스레드를 할당한다. 커넥션을 처리 할 때 만들어진 수많은 프로세스나 스레드는 많은 메모리나 시스템 리소스를 소비한다. 많은 멀티스레드 웹 서비스가 스레드/프로세스의 최대 개수에 제한을 건다. 다중 I/O 서버 커넥션의 상태가 바뀌면, 그 커넥션에 대한 작은 양의처리가 수행된다. 그 처리가 완료되면, 커넥션은 다음 상태 변경을 위해 열린 커넥션 목록으로 돌아간다. 스레드와 프로세스는 유휴 상태의 커넥션에 얽혀 기다리느라 리소스를 낭비하지 않는다. 다중 멀티스레드 웹서버 CPU 여러 개의 이점을 살리기 위해 멀티스레딩과 다중화를 결합한다. 여러 개의 스레드는 각각 열려있는 커넥션을 감시하고 각 커넥션에 대해 조금씩 작업을 수행한다. 5.4 단계 3: 요청 처리웹 서버가 요청을 받으면, 서버는 요청으로부터 메서드, 리소스, 헤더, 본문을 얻어내어 처리한다. 5.5 단계 4: 리소스의 매핑과 접근웹 서버는 리소스 서버다. 클라이언트가 웹 서버에 리소스를 요청하면, 웹 서버는 요청 메시지의 URI에 대응하는 알맞는 콘텐츠나 콘텐츠 생성기를 찾아서 클라이언트로 전달한다. 5.5.1 Docroot 리소스 매핑을 하는데 요청 URI를 웹 서버의 파일 시스템 안에 있는 파일 이름으로 사용하는 것이 가장 쉽다. 일반적으로 웹 서버 파일 시스템의 특별한 폴더를 웹 콘텐츠를 위해 예약해 둔다. 이 폴더는 문서 루트 혹은 docroot로 불린다. 가상 호스팅된 docroot 각 사이트에 그들만의 분리된 문서 루트를 주는 방법이다. 하나의 웹 서버 위에서 두 개의 사이트가 완전히 분리된 콘텐츠를 갖고 호스팅 되도록 할 수 있다. 사용자 홈 디렉터리 docroots 사용자들이 한 대의 웹 서버에서 각자의 개인 웹사이트를 만들 수 있도록 해주는 것이다. 보통 사용자 이름이 오는 것으로 시작하는 URI는 그 사용자의 개인 문서 루트를 가리킨다. GET /~jeus/index.html HTTP/1.0 5.5.2 디렉터리 목록 웹 서버는 경로가 파일이 아닌 디렉터리 URL에 대한 요청을 받을 수 있다. 사용자가 어떤 디렉터리에 대한 URL을 요청했는데, 그 디렉터리가 index.html이란 이름을 가진 파일을 갖고 있다면, 서버는 그 파일의 콘텐츠를 반환한다. 웹 서버는 기본 디렉터리 파일로 사용될 파일 이름의 집합인 DirectoryIndex 지시자를 사용해서 색인 파일로 사용될 모든 파일의 이름을 우선순위로 나열한다. 5.5.3 동적 콘텐츠 리소스 매핑 웹 서버는 URI를 동적 리소스에 매핑할 수 있다. 애플리케이션 서버라고 불리는 것들은 웹 서버를 복잡한 백엔드 애플리케이션과 연결하는 일을 한다. 5.5.4 서버사이드 인클루드(Server-Side Includes, SSI) 어떤 리소스가 서버사이드 인클루드를 포함하고 있다면, 서버는 그 리소스의 콘텐츠를 클라이언트에게 보내기 전에 처리한다. 서버는 콘텐츠에 변수 이름이나 내장된 스크립트가 될 수 있는 어떤 특별한 패턴이 있는지 검사를 받는다. 5.5.5 접근제어 접근제어 되는 리소스에 대한 요청이 도착했을 때 웹 서버는 클라이언트의 IP주소에 근거하여 접근을 제어할 수 있고 혹은 리소스에 접근하기 위한 비밀번호를 물어볼 수 있다. 5.6 단계 5: 응답 만들기5.6.1 응답 엔터티만약 트랜잭션이 응답 본문을 생성한다면, 그 내용을 응답 메시지와 함께 돌려보낸다. 응답 본문의 MIME 타입을 서술하는 Content-Type 헤더 응답 본문의 길이를 서술하는 Content-Length 헤더 실제 응답 본문의 내용 5.6.2 MIME 타입 결정하기mime.types 웹 서버는 각 리소스의 MIME 타입을 계산하기 위해 확장자별 MIME 타입이 담겨 잇는 파일을 탐색한다. 매직 타이핑 웹 서버는 각 파일의 MIME 타입을 알아내기 위해 파일의 내용을 검사해서 알려진 패턴에 대한 테이블에 해당하는 패턴이 있는지 찾아 볼 수 있다. 유형 명시 특정 파일이나 디렉터리 안의 파일들이 파일 확장자나 내용에 상관없이 어떤 MIME 타입을 갖도록 웹 서버를 설정할 수 있다. 유형 협상(Type negotiation) 웹 서버는 한 리소스가 여러 종류의 문서 형식에 속하도록 설정할 수 있다. 5.6.3 리다이렉션 웹 서버는 요청을 수행하기 위해 브라우저가 다른 곳으로 가도록 리다이렉트 할 수 있다. 리다이렉션 응답은 3XX 상태코드로 지칭된다. 영구히 리소스가 옮겨진 경우 리소스는 새 URL이 부여되어 새로운 위치로 옮겨졌거나 이름이 바뀔 수 있다. 웹 서버는 클라이언트에게 리소스 위치가 변경되었음을 알려준다. 301 Moved Permanently 상태 코드가 사용된다. 임시로 리소스가 옮겨진 경우 리소스가 임시로 옮겨지거나 이름이 변경되었지만, 서버는 클라이언트가 나중에는 원래 URL로 찾아오고 북마크도 갱신하길 원치 않는다. 303 See Ohter 와 307 Temporary Redirect 상태 코드가 사용된다. URL 증강 서버는 종종 문맥 정보를 포함ㅎ시키기 위해 재 작성된 URL로 리다이렉트한다. 요청이 도착했을 때, 서버는 상태 정보를 내포한 새 URL을 생성하고 사용자를 이 새 URL로 리다이렉트한다. 클라이언트는 상태정보가 추가된 완전한 URL을 포함한 요청을 다시 보낸다. 303 See Ohter 와 307 Temporary Redirect 상태 코드가 사용된다. 부하 균형 서버가 과부화된 요청을 받으면, 서버는 클라이언트를 덜 부하가 걸린 서버로 리다이렉트 할 수 있다. 303 See Ohter 와 307 Temporary Redirect 상태 코드가 사용된다. 친밀한 다른 서버가 있을때 서버는 클라이언트에 대한 정보를 갖고 있는 다른 서버로 리다이렉트 할 수 있다. 303 See Ohter 와 307 Temporary Redirect 상태 코드가 사용된다. 디렉터리 이름 정규화 클라이언트가 디렉터리 이름에 대한 URI를 요청하는데 /을 빠뜨렸다면, 웹 서버는 /를 추가한 URI로 리다이렉트한다. 5.7 단계 6: 응답 보내기 서버는 여러 클라이언트에 대한 많은 커넥션을 가질 수 있다. 서버는 커넥션 상태를 추적해야 하며 지속적인 커넥션은 특별히 주의해서 다룰 필요가 있다. 비지속적인 커넥션이라면, 서버는 모든 메시지를 전송했을 때 자신쪽의 커넥션을 닫을 것이다. 지속적인 커넥션이라면, 서버가 Content-length 헤더를 바르게 계산하기 위해 특별한 주의를 필요로 하는 경우나, 클라이언트가 응답이 언제 끝나는지 알 수 없는 경우에, 커넥션은 열린 상태를 유지한다. 5.8 단계 7: 로깅트랜잭션이 완료 되었을 때 웹 서버는 트랜잭션이 어떻게 수행되었는지에 대한 로그를 로그파일에 기록한다.","link":"/2019/09/08/http-guide-chap5/"},{"title":"HTTP 완벽가이드 7장 part2","text":"7장 캐시 part27.7 캐시처리 단계 단계 1: 요청받기캐시는 네트워크로부터 들어오는 데이터를 읽어들인다. 단계 2: 파싱캐시는 요청 메시지를 여러 부분으로 파싱하여 헤더 부분을 조작하기 쉬운 자료 구조에 담는다. 단계 3: 검색캐시는 URL을 알아내고 그에 해당하는 로컬 사본이 있는지 검사한다. 만약 문서를 로컬에서 가져올 수 없다면, 캐시는 원 서버나 부모 프락시에서 가져오거나 혹은 실패를 반환한다. 캐시된 객체는 서버 응답 본문과 원 서버 응답 헤더를 포함하고 있으므로, 캐시 적중 동안 올바른 서버 헤더가 반환될 수 있다. 단계 4: 신선도 검사HTTP는 캐시가 일정 기간 동안 서버 문서의 사본을 보유할 수 있도록 해준다. 이 기간 동안, 문서는 신선한 것으로 간주되고 서버를 통하지 않고 이 문서를 제공할 수 있다. 캐시된 사본을 신선도 한계를 넘을 정도로 오래 갖고 있었다면, 그 객체는 신선하지 않은 것으로 간주되며, 캐시는 그 문서를 제공하기 전에 문서에 어떤 변경이 있었는지 검사하기 위해 서버와 재검사를 해야 한다. 단계 5: 응답 생성캐시는 캐시된 서버 응답 헤더를 토대로 응답 헤더를 생성한다. 캐시는 클라이언트에 맞게 이 헤더를 조정해야 하는 책임이 있다. 캐시는 캐시 신선도 정보(Cache-Control, Age, Expires 헤더)를 삽입하며, 요청이 프락시 캐시를 거쳐갔음을 알려주기 위해 종종 Via 헤더를 포함시킨다. 단계 6: 전송캐시는 응답 헤더가 준비되면, 응답을 클라이언트에게 돌려준다. 단계 7: 로깅대부분의 캐시는 로그 파일과 캐시 사용에 대한 통계를 유지한다. 각 캐시 트랜잭션이 완료된 후, 통계 캐시 적중과 부적중 횟수에 대한 통계를 갱신하고 로그 파일에 요청 종류, URL 그리고 무엇이 일어났는지를 알려주는 항목을 추가한다. 캐시 처리 플로 차트 7.8 사본을 신선하게 유지하기캐시된 사본 모두가 서버의 문서와 항상 일치하는 것이 아니므로 캐시된 데이터는 서버의 데이터와 일치하도록 관리되어야 한다. HTTP는 캐시된 사본이 서버와 일치하도록 문서 만료와 서버 재검사라는 단순한 메커니즘을 갖는다. 1. 문서 만료HTTP는 Cache-Control과 Expires라는 헤더들을 이용해서 원 서버가 각 문서에 유효기간을 붙일 수 있게 한다. 이 헤더들은 콘텐츠가 얼마 오랫동안 신선한 상태로 보일 수 있는지 좌우한다. 2. 유효기간과 나이 Cache-Control: max-age max-age 값은 문서의 최대 나이를 정의한다. 문서가 처음 생성된 이후부터, 제공하기엔 더 이상 신선하지 않다고 간주될 때가지 경과한 시간의 최대값(초)이다. Cache-Control: max-age=484200 Expires 절대 유효기간을 명시한다. 만약 유효기간이 경과했다면, 그 문서는 더 이상 신선하지 않다. Expires: Fri, 05 Oct 2019, 05:00:00 GMT 3. 서버 재검사캐시된 문서가 만료되었다는 것은 검사할 시간이 되었음을 의미하며, 캐시가 원 서버에게 문서가 변경되었는지 여부를 확인하는 서버 재검사를 한다. 재검사 결과 문서가 변경되었다면, 캐시는 그 문서의 새로운 사본을 가져와 오래된 데이터 대신 저장한 뒤 클라이언트에게 보내준다. 재검사 결과 문서가 변경되지 않았다면, 캐시는 새 만료일을 포함한 새 헤더들만 가져와서 캐시 안의 헤더들을 갱신한다. 캐시는 문서의 신선도를 매 요청마다 검증할 필요가 없으며, 문서가 만료되었을 때 한번만 서버와 재검사를 하면 되기 때문에 서버 트래픽을 절약하고 사용자 응답 시간을 개선한다. 4. 조건부 메서드와의 재검사 HTTP는 캐시가 서버에게 조건부 GET 이라는 요청을 보낼 수 있도록 해준다. 이 요청은 서버가 갖고있는 문서가 캐시가 갖고 있는 것과 다른 경우에만 객체 본문을 보내달라고 하는 것이다. 조건부 GET은 GET 요청 메시지에 특별한 조건부 헤더를 추가함으로써 시작된다. HTTP는 다섯 가지 조건부 요청 헤더 중 If-Modified-Since와 If-None-Match를 가장 유용하게 사용한다. 5. If-Modified-Since: 날짜 재검사IMS요청은 서버에게 리소스가 특정 날짜 이후로 변경된 경우에만 요청한 본문을 보내달라고 한다. 만약 문서가 주어진 날짜 이후에 변경되었다면, If-Modified-Since 조건은 참이고, GET 요청은 성공한다. 새 문서가, 새로운 만료 날짜와 그 외 다른 정보들이 담긴 헤더들과 함께 캐시에게 반환된다. 만약 문서가 주어진 날짜 이후에 변경되지 않았다면 조건은 거짓이고, 서버는 304 Not Modified 응답 메시지를 클라이언트에 돌려준다. 효율을 위해 본문은 보내지 않는다. If-Modified-Since 헤더는 Last-Modified 헤더와 함께 동작한다. 서버가 최근 변경 일시를 붙인다. 6. If-None-Match: 엔터티 태그 재검사퍼블리셔가 문서를 변경했을 때, 그는 문서의 엔터티 태그를 새로운 버전으로 표현 할 수 있다. 엔터티 태그가 변경되었다면, 캐시는 새 문서의 사본을 얻기 위해 If-None-Match 조건부 헤더를 사용할 수 있다. 캐시는 엔터티 태그 ‘V2.6’인 문서를 갖고있다. 캐시는 서버에게 엔터티 태그가 ‘V2.6’이 아닌 경우에만 새 객체를 달라는 요청 방식으로 유효한지 여부를 재검사한다. 서버의 엔터티 태그가 변하지 않았다면, 304 Not Modified 응답이 반환된다. 캐시가 객체에 대한 여러 개의 사본을 갖고 있는 경우, 하나의 If-None-Match에 여러개의 엔터티 태그를 포함 시킬 수 있다. If-None-Match: &quot;V2.4&quot;, &quot;V2.5&quot;, &quot;V2.6&quot; 7. 약한 검사기와 강한 검사기서버는 때때로 모든 캐시된 사본을 무효화시키지 않고 문서를 살짝 고칠 수 있도록 허용하고 싶은 경우가 있다. 약한 검사기 콘텐츠가 조금 변경되었더라도 그 정도면 같은 것이라고 서버가 주장할 수 있도록 해준다 서버는 W/ 접두사로 약한 검사기를 구분한다. If-None-Match: W/&quot;v1.0&quot; 강한 검사기 콘텐츠가 바뀔 때마다 바뀐다. 8. 언제 엔터티 태그를 사용하고 언제 Last-Modified 일시를 사용하는가HTTP 클라이언트는 서버가 엔터티 태그를 반환했다면, 반드시 엔터티 태그 검사기를 사용해야 한다. 서버가 Last-Modified 값만을 반환했다면, 클라이언트는 If-Modified-Since 검사를 사용할 수 있다. 7.9 캐시 제어HTTP는 문서가 만료되기 전까지 얼마나 오랫동안 캐시될 수 있게 할 것인지 서버가 설정할 수 있는 여러 가지 방법을 정의한다. 1. no-cache와 no-store 응답 헤더Cache-Control: no-store Cache-Control: no-cache Pragma: no-cache no-store가 표시된 응답은 캐시가 그 응답의 사본을 만드는 것을 금지한다. no-cache로 표시된 응답은 사실 로컬 캐시 저장소에 저장될 수 있다. Pragma: no-cache 헤더는 HTTP/1.0+와의 하위호환성을 위해 HTTP/1.1에 포함되어 있다. 2. Max-Age 응답 헤더신선하다고 간주되었던 문서가 서버로부터 온 이후로 흐른 시간이고, 초를 나타낸다. s-maxage 헤더는 max-age와 같지만, 공유된(공용) 캐시에만 적용된다. Cache-Control: max-age=3600 Cache-Control: s-maxage=3600서버는 최대 maximum aging을 0으로 설정함으로써, 캐시가 매 접근마다 문서를 캐시하거나 리프레시하지 않도록 요청할 수 있다. 3. Expires 응답 헤더(deprecated) Expires 헤더는 초 단위의 시간 대신 실제 만료 날짜를 명시한다. HTTP를 설계한 사람들은 많은 서버가 동기화 되어 있지 않거나 부정확한 시계를 갖고 있기 때문에, 만료를 절대시간 대신 경과된 시간으로 표현하는 것이 낫다고 판단한다. Expires: Fri 05 Oct 2019, 05:00:00 GMT 4. Must-Revalidate 응답 헤더캐시는 성능을 개선하기 위해 신선하지 않은 객체를 제공하도록 설정될 수 있다. 캐시가 만료 정보를 엄격하게 따르길 원한다면, 원 서버는 Cache-Control: must-revalidate 를 붙인다. 캐시가 이 객체의 신선하지 않은 사본을 원 서버와의 최초의 재검사 없이는 제공해서는 안 됨을 의미한다. 5. 휴리스틱 만료만약 응답이 max-age 헤더나 expires 헤더 중 어느 것도 포함하지 않고 있다면, 캐시는 경험적인 방법으로(heurisitic) 최대 나이를 계산한다. 7.10 자세한 알고리즘1. 나이와 신선도 수명캐시된 문서가 신선하지 알려주려면, 캐시는 사본의 나이와 신선도 수명 단 두 가지만 계산하면 된다. $충분히_신선한가 = ($나이 &lt; $신선도_수명)문서의 나이 = 서버가 문서를 보낸 후 그 문서가 나이를 먹은 시간의 총합 신선도 수명 = 아직 문서가 신선하다고 볼 수 있는 수명 2. 나이 계산 응답이 서버에서 생서되었을 때부터 지금까지의 총 시간 인터넷상의 라우터들과 게이트웨들 사이를 떠돌아다닌 시간과 응답이 캐시에 머물렀던 시간을 포함 $겉보기_나이 = max(0, $응답을_받은_시각 - $Date_헤더값); $보정된_겉보기_나이 = max($겉보기_나이, $Age_헤더값); $응답_지연_추정값 = ($응답을_받은_시각 - $요청을_보낸_시각); $문서가_우리의_캐시에_도착했을_때의_나이 = $보정된_겉보기_나이 + $응답_지연_추정값; $사본이_우리의_캐시에_머무른_시간 = $현재_시각 - $응답을_받은_시각; $나이 = $문서가_우리의_캐시에_도착했을_때의_나이 + $사본이_우리의_캐시에_머무른_시간; 3. 완전한 나이 계산 알고리즘문서에 대한 요청이 캐시에 도착했을 때, 문서의 현재 나이를 계산하기 위해 그 문서가 캐시에 얼마나 오랫동안 머물렀는지 알 필요가 있다. $나이 = $문서가_우리의_캐시에_도착했을_때의_나이 + $사본이_얼마나_오래_우리의_캐시에_있었는지; 언제 문서가 캐시에 도착했는지 = $time_got_response 언제 현재 요청이 도착했는지 = $current_time","link":"/2019/10/06/http-guide-chap7-2/"},{"title":"HTTP 완벽가이드 6장","text":"6장 프락시6.1 웹 중개자 웹 프락시 서버는 클라이언트 입장에서 트랜잭션을 수행하는 중개인이다. 프락시는 클라이언트의 요청을 받게 되므로, 웹 서버처럼 요청과 커넥션을 적절히 다루고 응답을 돌려줘야 한다. 프락시는 요청을 서버로 보내기도 하므로, 요청을 보내고 응답을 받는 HTTP 클라이언트 처럼 동작해야 한다. 6.1.1. 개인프락시와 공유 프락시공용 프락시 중앙 집중형 프락시를 관리하는 게 비용효율이 높고 쉽다. 여러 사용자들에게 공통된 요청에서 이득을 취하기 쉬우므로, 캐시 프락시 서버와 같은 프락시 서버는 사용자가 많을수록 효율이 좋다. 개인 프락시 하나의 클라이언트만을 위하므로 개인 전용 프락시는 흔하지 않다. 6.1.2 프락시 대 게이트웨이프락시 같은 프로토콜을 사용하는 둘 이상의 애플리케이션을 연결한다. 클라이언트와 서버 양쪽 모두에게 HTTP로 통신한다. 게이트웨이 서로 다른 프로토콜을 사용한는 둘 이상의 애플리케이션을 연결한다. 클라이언트와는 HTTP로 서버와는 POP으로 서로 다른 프로토콜로 말하더라도 서로 간의 트랜잭션을 완료하도록 한다. 6.2 왜 프락시를 사용하는가?보안을 개선하고, 성능을 높여주며, 비용을 절약한다. 모든 HTTP 트래픽을 보고 건드릴 수 있기 때문에, 유용한 웹 서비스를 구현하기 위해 트래픽을 감시하고 수정한다. ex) 교육 콘텐츠에는 제한 없는 접근을 허용하면서 어린이에게 부적절한 사이트의 접근을 강제로 거부한다. 대기업이나 분산된 조직에서 관리되는 다양한 종류의 수많은 웹 서버들에 대한 접근 제어를 수시로 갱신 할 필요 없이, 중앙 프락시 서버에서 접근 제어를 설정할 수 있다. 바이러스를 제거하는 웹이나 이메일 프락시가 사용할 수 있는 트래픽을 세심하게 살펴볼 수 있는 훅을 제공한다. 인터넷 트래픽 조건과 콘텐츠의 종류에 따라 요청을 특정 웹 서버로 유도하는 콘텐츠 라우터로 동작할 수 있다. 6.3 프락시는 어디에 있는가?6.3.1 프락시 서버 배치출구 프락시 로컬 네트워크와 더 큰 인터넷 사이를 오가는 트래픽을 제어하기 위해 프락시를 로컬 네트워크의 출구에 넣을 수 있다. 접근(입구) 프락시 고객으로 부터의 모든 요청을 종합적으로 처리하기 위해 프락시는 ISP 접근 지점에 위치한다. 대리 프락시 네트워크의 가장 끝에 있는 웹 서버들의 바로 앞에 위치하여 웹 서버로 향하는 모든 요청을 처리하고 필요 할 때만 웹 서버에게 자원을 요청할 수 있다. 네트워크 교환 프락시 캐시를 이용해 인터넷 교차로의 혼잡을 완화하고 트래픽 흐름을 감시한다. 6.3.2 프락시 계층 프락시들이 연쇄적으로 구성되어있다. 프락시 서버들은 부모와 자식의 관계를 갖는다. 각각의 프락시 서버들의 여러가지 판단 근거에 의해 메시지를 다양하고 유동적으로 전송한다. 6.3.3 어떻게 프락시가 트래픽을 처리하는가클라이언트 트래픽이 프락시로 가도록 만드는 방법이 네 가지 존재한다. 클라이언트를 수정한다 대부분의 브라우저들은 수동 또는 자동 프락시 설정을 지원한다. 클라이언트는 HTTP 요청을 프락시로 보낸다. 네트워크를 수정한다 HTTP 트래픽을 지켜보고 가로채어 클라이언트 모르게 트래픽을 프락시로 보낸다.(인터셉트 프락시) DNS 이름공간을 수정한다 웹 서버 앞에 위치하는 대리 프락시 서버는 웹 서버의 이름과 IP주소를 자신이 직접 사용한다. 웹 서버를 수정한다 HTTP 리다이렉션 명령을 클라이언트에게 돌려줌으로써 클라이언트의 요청을 프락시로 리다이렉트 하도록 설장할 수 있다. 6.4 클라이언트 프락시 설정많은 브라우저가 프락시를 설정하는 여러가지 방법을 제공한다. 각 브라우저의 설정 메뉴에서 프락시 사용에 대한 설정을 할 수 있다. PAC파일을 사용하면 프락시 설정을 상황에 맞게 자바스크립트 함수가 계산해서 적절한 프락시 서버를 선택한다. WPAD는 브라우저에게 알맞은 PAC 파일을 자동으로 찾아준다. 6.5 프락시 요청의 미묘한 특징들6.5.1 프락시 URI는 서버 URI와 다르다6.5.2 가상 호스팅에서 일어나는 같은 문제 스킴/호스트/포트번호 누락 문제는 가상으로 호스팅 되는 웹 서버의 문제와 같은 문제다. 6.5.3 인터셉트 프락시는 부분 URI를 받는다6.5.4 프락시는 프락시 요청과 서버 요청을 모두 다룰 수 있다 트래픽이 프락시 서버로 리다이렉트 될 수 잇는 여러가지 방법이 존재하기 때문에 다목적 프락시 서버는 요청 메시지의 와전한 URI와 부분 URI 모두 지원해야한다. 완전한 URI가 주어졌다면, 그것을 사용한다. 부분 URI 주어졌고 Host 헤더가 있다면, Host 헤더를 이용해 원 서버의 이름과 포트번호를 알아야한다. 부분 URI가 주어졌으나 Host 헤더가 없다면, 원 서버를 알아내야 한다. 6.5.5 전송 중 URI 변경6.5.6 URI 클라이언트 자동확장과 호스트 명 분석6.5.7 프락시 없는 URI 분석6.5.8 명시적인 프락시를 사용할 때의 URI 분석6.5.9 인터셉트 프락시를 이용한 URI 분석6.6 메시지 추적 웹 요청시에 클라이언트에 서버로 향하는 도중에 둘 이상의 프락시를 거치는 것은 흔해졌다. 프락시가 흔해지면서, 서로 다른 스위치와 라우터를 넘나드는 IP 패킷의 흐름을 추적하는것 못지않게 프락시를 넘나드는 메시지의 흐름을 추적하고 문제점을 찾아내는 것이 중요하다. 6.6.1 Via 헤더 메시지가 지나는 각 중간 노드의 정보를 나열한다. 6.7 프락시 인증 프락시는 접근 제어 장치로서 제공될 수 있다. HTTP는 사용자가 유효한 접근 권한 자격을 프락시에 제출하지 않는 한 콘텐츠에 대한 요청을 차단하는 프락시 인증을 제공한다. 6.8 프락시 상호운용성 클라이언트, 서버, 프락시는 여러 버전으로 여러 벤더 회사에 의해 만들어진다. 제각각의 버그들이 생기므로 프락시 서버는 클라이언트와 서버를 중개해야 한다. 6.8.1 지원하지 않는 헤더와 메서드 다루기 프락시 서버는 넘어오는 헤더 필드들을 모두 이해하지 못할 수 있다. 이해할 수 없는 헤더 필드는 반드시 그대로 전달해야 하며, 같은 이름의 헤더 필드가 여러개 있는 경우에는 그들의 상대적인 순서도 반드시 유지해야한다. 6.8.2 Options: 어떤 기능을 지원하는지 알아보기 HTTP OPTIONS 메서드는 서버나 웹 서버의 특정 리소스가 어떤 기능을 지원하는지 알아볼 수 있게 해준다. 요청의 URI가 별표(*)라면, 요청은 서버 전체의 능력에 대해 묻는 것이 된다. OPTIONS * HTTP/1.1 URI가 실제 리소스라면, 특정 리소스에 대해 가능한 기능들을 묻는 것이다. OPTIONS [http://bebiangel.github.io](http://bebiangel.github.io/index.html) HTTP/1.1 static HTML file wouldn't accept a POST method. 6.8.3 Allow 헤더 요청 URI에 의해 식별되는 자원에 대해 지원되는 메서드들이나 서버가 지원하는 모든 메서드를 열거한다. Allow: GET, HEAD, PUT 클라이언트는 원 서버와 대화하는 다른 경로를 갖고 있을 수 있기 때문에, 프락시는 Allow 헤더 필드를 수정할 수 없다.","link":"/2019/09/22/http-guide-chap6/"},{"title":"HTTP 완벽가이드 9장","text":"9장 웹 로봇1. 크롤러와 크롤링 웹 크롤러란? 웹페이지를 한 개 가져오고, 그 다음 그 페이지가 가리키는 모든 웹페이지를 가져오는 작업을 재귀적으로 반복하는 방식으로 웹을 순회하는 로봇이다. 인터넷 검색엔진은 웹을 돌아다니면서 모든 문서를 끌어오기 위해 크롤러를 사용한다. 사용자가 특정 단어로 검색을 할때, 가져와야 하는 페이지들이 수십억 개나 되므로, 검색엔진 로봇들은 가장 복잡한 로봇들중 하나가 되었다. 1.1 어디에서 시작하는가: ‘루트 집합’ 크롤러가 방문을 시작하는 URL들의 초기 집합을 루트 집합이라고 한다. 모든 링크를 크롤링하면 관심있는 웹페이지들의 대부분을 가져오게 될 수 있도록 충분히 다른 장소에서 URL들을 선택해야 한다. 일반적으로 좋은 루트 집합은 크고 인기 있는 웹 사이트, 새로 생성된 페이지들의 목록, 자주 링크되지 않는 잘 알려지 있지 않은 페이지들의 목록으로 구성된다. 1.2 링크 추출과 상대 링크 정상화 크롤러는 검색한 각 페이지 안에서 크롤링할 URL 링크들을 추가한다. HTML 파싱을 해서 링크들을 추출하고 상대 링크를 절대 링크로 바꿔야 하낟. 1.3 루프와 중복 순환은 크롤러를 루프에 빠뜨려서 빙빙 돌게 만들거나, 같은 페이지를 반복해서 가져오는데 시간을 허비하도록 만들 수 있다. 같은 페이지를 반복해서 가져오면, 웹 서버에 부담이 가고, 웹 사이트를 압박하여 실제 사용자도 사이트에 접근할 수 없도록 막아버리게 만들 수 도 있다. 크롤러는 루프 자체가 문제가 되지 않더라도, 많은 중복된 페이지들을 가져오게 되므로, 애플리케이션이 중복된 컨텐츠로 넘쳐나게 만들수 있다. 1.5 빵 부스러기의 흔적 전 세계 웹 콘텐츠들을 크롤링하기 위해서는 빠른 속도가 중요하다. 웹 크롤러들은 방문한 곳을 관리하기 위해 사용하는 유용한 기법들이 있다. 트리와 해시 테이블 복잡한 로봇들은 방문한 URL을 추적하기 위해 검색 트리나 해시 테이블을 사용한다. 느슨한 존재 비트맵 공간 사용을 최소화하기 위해 존재 비트 배열과 같은 느슨한 자료구조를 사용한다. 체크포인트 로봇 프로그램이 갑작스럽게 중단될 경우를 대비해, 방문한 URL의 목록이 디스크에 저장되었는지 확인한다. 파티셔닝 각각이 분리된 한 대의 컴퓨터인 로봇들이 동시에 일하고 있는 농장(farm)을 이용한다. 각 로봇엔 URL들의 특정 한 부분이 할당되어 그에 대한 책임을 갖는다. 2. 로봇의 HTTP 로봇들은 HTTP 요청을 만들고 스스로를 클라이언트로서 적절한 HTTP 요청 헤더를 사용해야 한다. 2.1 요청 헤더 식별하기 로봇 대부분은 약간의 신원 식별 헤더(능력, 신원, 출신)를 구현하고 전송한다. 이 정보들은 크롤러의 소유자를 찾아낼 때와 서버에게 로봇이 어떤 종류의 콘텐츠를 다룰 수 있는지에 대한 약간의 정보를 주려 할 때 유용하다. User-Agent 서버에게 요청을 만든 로봇의 이름 From 로봇의 사용자/관리자의 이메일 주소를 제공한다. Accept 서버에게 어떤 미디어 타입을 보내도 되는지 말해준다. Referer 현재의 요청 URL을 포함한 문서의 URL을 제공한다. 2.2 가상 호스팅 로봇은 Host 헤더를 지원해야 한다. 요청에 Host 헤더를 포함 하지 않으면 로봇이 어떤 URL에 대해 잘못된 콘텐츠를 찾게된다. 2.3 조건부 요청 수십억 개의 웹페이지를 다운 받을 수 도 있으므로, 콘텐츠가 변경되었을때만 가져오도록 하는 것이 효과적이다. 시간이나 엔터티 태그를 비교함으로써 그들이 받아간 마지막 버전 이후에 업데이트 된 것이 있는지 알아보는 조건부 HTTP요청을 구현한다. 2.4 응답 다루기 로봇들은 주 관심사가 단순히 GET 메서드로 콘텐츠를 요청해서 가져오는 것이므로 응답다루기 를 거의 하지 않는다. 로봇들은 최소한 일반적인 상태 코드나 예상할 수 있는 상태 코드를 다룰 수 있어야한다. HTTP 헤더에 임베딩된 정보를 따라 로봇들은 엔터티 자체의 정보를 찾을 수 있다. 메타 http-equiv 태그와 같은 메타 HTML 태그는 리소스에 대해 콘텐츠 저자가 포함시킨 정보다. 2.5 User-Agent 타기팅 웹 사이트들은 그들의 여러 기능을 지원할 수 있도록 브라우저의 종류를 감지하여 그에 맞게 콘텐츠를 최적화한다. 사이트는 로봇에게 콘텐츠 대신 에러 페이지를 제공한다. 3. 부적절하게 동작하는 로봇들폭주하는 로봇 로봇이 논리적인 에러를 갖고 있거나 순환에 빠졌다면 웹 서버에 극심한 부하를 안겨준다. 서버에 과부하를 유발하여 다른 누구에게도 서비스를 못하게 만드는 일이 발생할 수 있다. 오래된 URL 웹 사이트의 콘텐츠들이 많이 바뀌었다면, 로봇들은 존재하지 않은 URL에 대한 요청을 많이 보낼 수 있다. 존재하지 않는 문서에 대한 접근 요청이나, 에러 페이지를 제공하는 부하로 인해 웹 서버의 수용 능력이 감소될 수 있다. 길고 잘못된 URL 웹 사이트에게 크고 의미 없는 URL을 요청한다면, 웹 서버의 처리 능력에 영향을 주고, 접근 로그를 어지럽게 채우게 된다. 호기심이 지나친 로봇 로봇들은 사적인 데이터에 대한 URL을 얻어 인터넷 검색엔진이나 기타 애플리케이션을 통해 쉽게 접근할 수 있도록 만들 수 있다. 로봇들이 비밀번호 파일이나 신용카드 정보와 같이 민감한 데이터를 가져가는 것이 가능하다는 것을 사이트 구현자들이 인지해야 할 필요가 있다. 동적 게이트웨이 접근 로봇은 게이트웨이의 콘텐츠에 대한 URL로 요청을 할 수 있다. 보통 특수 목적을 위한 경우이므로 처리 비용이 많이 든다. 4. 로봇 차단하기 robots.txt 는 로봇의 접근을 제어하는 정보를 저장하는 파일의 이름이다. 어떤 로봇이 서버의 어떤 부분에 접근할 수 있는지에 대한 정보가 담겨있다. 웹 사이트의 어떤 리소스에 접근하기 전에 해당 사이트의 robots.txt를 요청하고, 해당 사이트의 웹 페이지를 가져올 수 잇는 권한이 있는지 확인하고 페이지를 가져온다. 4.1 웹 사이트와 robots.txt 파일들 웹 사이트의 어떤 URL을 방문하기 전에, 해당 사이트에 robots.txt 파일이 존재한다면 로봇은 반드시 그 파일을 가져와서 처리해야 한다. 4.2 robots.txt 파일 포맷User-Agent: Slurp User-Agent: webcrawler Disallow: /private User-Agent: * Disallow: 각 레코드는 특정 로봇들의 집합에 대한 차단 규칙의 집합을 기술한다. 각 레코드는 규칙 줄들의 집합으로 되어 있으며 빈 줄이나 파일 끝 문자로 끝난다. User-Agent 로봇의 이름은 로봇의 HTTP GET 요청 안의 User-Agent헤더를 통해 보내진다. 로봇이 자신의 이름에 대응하는 User-Agent줄을 찾지 못하였고 와일드 카드를 사용한 User-Agent: * 줄도 찾지 못했다면, 대응하는 레코드가 없는것이므로, 접근에는 어떤 제한도 없다. Disallow &amp; Allow User-Agent 줄 바로 다음에 온다. 특정 로봇에 대해 어떤 URL 경로가 명시적으로 금지되어 있고 명시적으로 허용되는지 기술한다. 5. 검색엔진 웹 로봇은 인터넷 검색엔진에서 사용자들이 어떠한 문서라도 찾을 수 있도록 도와준다. 5.1 검색 과정 검색엔진들은 전 세계의 웹페이지들에 대해 풀 텍스트 색인(full-text indexes) 라고 하는 로컬 데이터베이스를 생성한다. 검색엔진 크롤러들은 웹페이지들을 수집하여 풀 텍스트 색인에 추가한다. 크롤링을 한 번 하는데 걸리는 시간이 상당한 데 비해 웹페이지륻은 매 순간 변화하기 때문에, 풀 텍스트 색인은 웹의 특정 순간에 대한 스냅숏에 불과하다. 풀 텍스트 색인은 단어 하나를 입력받아 그 단어를 포함하고 있는 문서를 즉각 알려줄 수 있는 데이터베이스이다. 사용자가 질의를 보내고나면 게이트웨이 프로그램은 웹 UI질의를 풀 텍스트 색인을 검색할 때 ㅅ용되는 표현식으로 변환한다. 질의의 결과를 확인하기 위해 검색엔진이 색인을 한번 사용했다면, 게이트웨이 애플리케이션은 그 결과를 이용해 최종 사용자를 위한 결과 페이지를 즉석에서 만들어낸다.","link":"/2019/10/19/http-guide-chap9/"}],"tags":[{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"스터디","slug":"스터디","link":"/tags/스터디/"},{"name":"코드스피츠","slug":"코드스피츠","link":"/tags/코드스피츠/"}],"categories":[{"name":"스터디","slug":"스터디","link":"/categories/스터디/"},{"name":"코드스피츠","slug":"코드스피츠","link":"/categories/코드스피츠/"}]}